<!DOCTYPE html>
<html lang="sv">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéôÔ∏è Alice Hybrid Voice Test</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            min-height: 100vh;
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
        }

        .status-panel {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 20px;
            backdrop-filter: blur(10px);
        }

        .voice-controls {
            text-align: center;
            margin: 30px 0;
        }

        .voice-button {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            border: none;
            font-size: 48px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 0 10px;
        }

        .voice-button:hover {
            transform: scale(1.05);
        }

        .mic-button {
            background: linear-gradient(135deg, #ff6b6b, #ffa500);
            color: white;
        }

        .mic-button.recording {
            background: linear-gradient(135deg, #ff4757, #ff3742);
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(255, 71, 87, 0.7); }
            70% { box-shadow: 0 0 0 20px rgba(255, 71, 87, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 71, 87, 0); }
        }

        .log-panel {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            padding: 15px;
            margin: 20px 0;
            max-height: 400px;
            overflow-y: auto;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 12px;
        }

        .log-entry {
            margin: 5px 0;
            padding: 5px;
            border-left: 3px solid #4ecdc4;
            background: rgba(255, 255, 255, 0.05);
        }

        .log-entry.talk-lane {
            border-left-color: #ff6b6b;
        }

        .log-entry.tool-lane {
            border-left-color: #4ecdc4;
        }

        .log-entry.privacy {
            border-left-color: #ffa500;
        }

        .metrics {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }

        .metric-card {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px;
            border-radius: 10px;
            text-align: center;
        }

        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #4ecdc4;
        }

        .test-scenarios {
            margin-top: 30px;
        }

        .scenario-button {
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 10px 15px;
            margin: 5px;
            border-radius: 20px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.3s ease;
        }

        .scenario-button:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        .scenario-button.talk-lane {
            border-color: #ff6b6b;
        }

        .scenario-button.tool-lane {
            border-color: #4ecdc4;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üéôÔ∏è Alice Hybrid Voice Test</h1>
        <p>Testa Talk-lane (OpenAI Realtime) vs Tool-lane (Lokal gpt-oss)</p>
    </div>

    <div class="status-panel">
        <h3>üîå System Status</h3>
        <div id="connectionStatus">Ansluter...</div>
        <div id="routingStatus">Router: Standby</div>
        <div id="privacyStatus">Privacy Guard: Aktiv</div>
    </div>

    <div class="voice-controls">
        <button id="micButton" class="voice-button mic-button" onclick="toggleRecording()">
            üé§
        </button>
        <div>Tryck f√∂r att prata med Alice</div>
    </div>

    <div class="test-scenarios">
        <h3>üìã Testscenarier</h3>
        <div>
            <strong>Talk-lane (snabba svar):</strong><br>
            <button class="scenario-button talk-lane" onclick="testPhrase('Vad √§r klockan?')">Vad √§r klockan?</button>
            <button class="scenario-button talk-lane" onclick="testPhrase('Ber√§tta ett sk√§mt')">Ber√§tta ett sk√§mt</button>
            <button class="scenario-button talk-lane" onclick="testPhrase('Hur √§r v√§dret?')">Hur √§r v√§dret?</button>
        </div>
        <div style="margin-top: 15px;">
            <strong>Tool-lane (privat data):</strong><br>
            <button class="scenario-button tool-lane" onclick="testPhrase('Visa mina mejl fr√•n idag')">Visa mina mejl</button>
            <button class="scenario-button tool-lane" onclick="testPhrase('Vad har jag f√∂r m√∂ten imorgon?')">Mina m√∂ten</button>
            <button class="scenario-button tool-lane" onclick="testPhrase('Ring mig p√• 070-123-4567')">Ring mig (PII test)</button>
        </div>
    </div>

    <div class="metrics">
        <div class="metric-card">
            <div class="metric-value" id="talkLaneCount">0</div>
            <div>Talk-lane</div>
        </div>
        <div class="metric-card">
            <div class="metric-value" id="toolLaneCount">0</div>
            <div>Tool-lane</div>
        </div>
        <div class="metric-card">
            <div class="metric-value" id="privacyBlocks">0</div>
            <div>Privacy Blocks</div>
        </div>
        <div class="metric-card">
            <div class="metric-value" id="avgLatency">0ms</div>
            <div>Avg Latency</div>
        </div>
    </div>

    <div class="log-panel" id="logPanel">
        <div class="log-entry">üöÄ Alice Hybrid Voice System starting...</div>
        <div class="log-entry">üõ°Ô∏è Privacy Guard: Aktiv - All PII blockeras fr√•n OpenAI</div>
        <div class="log-entry">üîÄ Router: Klar att separera Talk-lane fr√•n Tool-lane</div>
    </div>

    <script>
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let wsConnection;
        let metrics = {
            talkLane: 0,
            toolLane: 0,
            privacyBlocks: 0,
            latencies: []
        };

        // Initialize WebSocket connections
        async function initializeConnections() {
            try {
                // Test voice gateway connection
                const response = await fetch('http://localhost:8001/health');
                const health = await response.json();
                
                if (health.status === 'healthy') {
                    log('‚úÖ Voice Gateway: Connected', 'talk-lane');
                    updateStatus('connectionStatus', '‚úÖ Voice Gateway Connected');
                } else {
                    log('‚ùå Voice Gateway: Unhealthy', 'privacy');
                    updateStatus('connectionStatus', '‚ùå Voice Gateway Disconnected');
                }
            } catch (error) {
                log(`‚ùå Connection error: ${error.message}`, 'privacy');
                updateStatus('connectionStatus', '‚ùå Connection Failed');
            }
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                await stopRecording();
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { 
                        sampleRate: 24000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await processAudio(audioBlob);
                };
                
                mediaRecorder.start();
                isRecording = true;
                
                document.getElementById('micButton').classList.add('recording');
                document.getElementById('micButton').innerHTML = '‚èπÔ∏è';
                
                log('üé§ Recording started...', 'talk-lane');
                updateStatus('routingStatus', 'Router: Recording');
                
            } catch (error) {
                log(`‚ùå Recording error: ${error.message}`, 'privacy');
            }
        }

        async function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                document.getElementById('micButton').classList.remove('recording');
                document.getElementById('micButton').innerHTML = 'üé§';
                
                log('‚èπÔ∏è Recording stopped, processing...', 'talk-lane');
                updateStatus('routingStatus', 'Router: Processing');
            }
        }

        async function processAudio(audioBlob) {
            const startTime = Date.now();
            
            try {
                // Simulate speech-to-text (i verkligheten skulle detta ske via WebRTC)
                log('üó£Ô∏è Simulating STT processing...', 'talk-lane');
                
                // F√∂r nu simulerar vi med en prompt - i riktiga systemet skulle vi anv√§nda WebRTC + STT
                const simulatedText = prompt("Vad sa du? (Simulerar speech-to-text)") || "Vad √§r klockan?";
                log(`üé§ Detected speech: "${simulatedText}"`, 'talk-lane');
                
                // Test routing logic
                await testRouting(simulatedText, startTime);
                
            } catch (error) {
                log(`‚ùå Processing error: ${error.message}`, 'privacy');
            }
        }

        async function testRouting(text, startTime) {
            try {
                // Call our new voice processing API with real responses
                const processResponse = await fetch('http://localhost:8001/api/voice/process', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text })
                });
                
                const processResult = await processResponse.json();
                const latency = Date.now() - startTime;
                
                log(`üîÄ Route Decision: ${processResult.route} (${processResult.intent})`, 
                    processResult.route === 'realtime' ? 'talk-lane' : 'tool-lane');
                
                if (processResult.no_cloud || processResult.privacy_override) {
                    log('üõ°Ô∏è Privacy Protection: Content kept local', 'privacy');
                    metrics.privacyBlocks++;
                    
                    if (processResult.guard_reason) {
                        log(`üö´ Guard reason: ${processResult.guard_reason}`, 'privacy');
                    }
                }
                
                if (processResult.route === 'realtime') {
                    metrics.talkLane++;
                    
                    if (processResult.processing_method === 'realtime_audio_stream') {
                        log(`‚ö° Talk-lane: OpenAI Realtime API - audio will stream via WebRTC`, 'talk-lane');
                        log(`üîä Note: Audio response handled by WebRTC connection`, 'talk-lane');
                        
                        // For now, simulate the response since WebRTC isn't fully connected
                        setTimeout(() => {
                            simulateRealtimeResponse(text);
                        }, 300);
                        
                    } else {
                        log(`‚ö° Talk-lane response: "${processResult.response}"`, 'talk-lane');
                        speakText(processResult.response);
                    }
                    
                } else {
                    metrics.toolLane++;
                    log(`üõ†Ô∏è Tool-lane processing: ${processResult.processing_method}`, 'tool-lane');
                    log(`ü§ñ Local response: "${processResult.response}"`, 'tool-lane');
                    speakText(processResult.response);
                }
                
                // Log reasoning
                if (processResult.reasoning) {
                    log(`üí≠ Reasoning: ${processResult.reasoning}`, 'tool-lane');
                }
                
                metrics.latencies.push(latency);
                updateMetrics();
                
            } catch (error) {
                log(`‚ùå Processing error: ${error.message}`, 'privacy');
            }
        }

        function simulateRealtimeResponse(text) {
            // Simulate OpenAI Realtime API response with dynamic answers
            const responses = {
                'vad √§r klockan': 'The time is 14:32',
                'what time is it': 'The time is 14:32', 
                'ber√§tta ett sk√§mt': 'Why did the Swedish programmer quit? Because he had too many IKEA bugs to fix!',
                'tell me a joke': 'Why did the Swedish programmer quit? Because he had too many IKEA bugs to fix!',
                'hur √§r v√§dret': 'The weather in Stockholm is cloudy today, around 15 degrees.',
                'how is the weather': 'The weather in Stockholm is cloudy today, around 15 degrees.',
                'vad √§r 25 + 17': 'Twenty-five plus seventeen equals forty-two.',
                'what\'s 25 + 17': 'Twenty-five plus seventeen equals forty-two.',
                'f√∂rklara kvantfysik': 'Quantum physics is the study of very small particles and their mysterious behavior.',
                'explain quantum physics': 'Quantum physics is the study of very small particles and their mysterious behavior.'
            };
            
            // Find matching response
            const textLower = text.toLowerCase().trim();
            let response = responses[textLower];
            
            // Fallback for partial matches
            if (!response) {
                for (const [key, value] of Object.entries(responses)) {
                    if (textLower.includes(key.split(' ')[0])) {
                        response = value;
                        break;
                    }
                }
            }
            
            // Default response
            if (!response) {
                response = "I'll help you with that. Let me process your request.";
            }
            
            setTimeout(() => {
                log(`üéµ Alice (English): "${response}"`, 'talk-lane');
                updateStatus('routingStatus', 'Router: Talk-lane Complete');
                
                // Spela upp svaret med Web Speech API
                speakText(response);
            }, 250);
        }

        function simulateToolResponse(text) {
            // Simulate local tool processing
            setTimeout(() => {
                log('üîí Local Processing: Tool executed safely', 'tool-lane');
                log('üìã Privacy Filter: Creating safe summary...', 'privacy');
                
                setTimeout(() => {
                    const toolResponse = "I found some information for you";
                    log(`üéµ Alice (English): "${toolResponse}"`, 'tool-lane');
                    updateStatus('routingStatus', 'Router: Tool-lane Complete');
                    
                    // Spela upp tool-lane svar ocks√•
                    speakText(toolResponse);
                }, 500);
            }, 800);
        }

        async function testPhrase(phrase) {
            log(`üß™ Testing: "${phrase}"`, 'talk-lane');
            await testRouting(phrase, Date.now());
        }

        function log(message, type = '') {
            const logPanel = document.getElementById('logPanel');
            const entry = document.createElement('div');
            entry.className = `log-entry ${type}`;
            entry.innerHTML = `${new Date().toLocaleTimeString()} - ${message}`;
            logPanel.appendChild(entry);
            logPanel.scrollTop = logPanel.scrollHeight;
        }

        function updateStatus(elementId, status) {
            document.getElementById(elementId).innerText = status;
        }

        function updateMetrics() {
            document.getElementById('talkLaneCount').innerText = metrics.talkLane;
            document.getElementById('toolLaneCount').innerText = metrics.toolLane;
            document.getElementById('privacyBlocks').innerText = metrics.privacyBlocks;
            
            if (metrics.latencies.length > 0) {
                const avgLatency = metrics.latencies.reduce((a, b) => a + b, 0) / metrics.latencies.length;
                document.getElementById('avgLatency').innerText = `${Math.round(avgLatency)}ms`;
            }
        }

        function speakText(text) {
            // Anv√§nd Web Speech API f√∂r att Alice ska prata h√∂gt
            if ('speechSynthesis' in window) {
                // Stoppa eventuell p√•g√•ende tal
                speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance(text);
                
                // S√§tt Alice r√∂st-inst√§llningar (engelsk kvinnlig r√∂st)
                utterance.lang = 'en-US';
                utterance.rate = 0.9;
                utterance.pitch = 1.1;
                utterance.volume = 0.8;
                
                // F√∂rs√∂k hitta en bra kvinnlig r√∂st
                const voices = speechSynthesis.getVoices();
                const femaleVoice = voices.find(voice => 
                    voice.lang.startsWith('en') && 
                    (voice.name.toLowerCase().includes('female') || 
                     voice.name.toLowerCase().includes('samantha') ||
                     voice.name.toLowerCase().includes('alex') ||
                     voice.name.toLowerCase().includes('karen'))
                );
                
                if (femaleVoice) {
                    utterance.voice = femaleVoice;
                }
                
                utterance.onstart = () => {
                    log('üîä Alice speaking...', 'talk-lane');
                };
                
                utterance.onend = () => {
                    log('üîá Alice finished speaking', 'talk-lane');
                };
                
                speechSynthesis.speak(utterance);
            } else {
                log('‚ö†Ô∏è Speech synthesis not supported', 'privacy');
            }
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', () => {
            initializeConnections();
            log('‚úÖ Hybrid Voice Test Client Loaded', 'talk-lane');
        });

        // Test privacy boundary immediately
        setTimeout(() => {
            log('üîí Testing Privacy Boundary...', 'privacy');
            testPhrase('Ring mig p√• 070-123-4567'); // Should be blocked
        }, 2000);
    </script>
</body>
</html>