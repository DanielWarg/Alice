<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéôÔ∏è Alice Real-time Voice Client</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            margin: 0;
            padding: 20px;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .connection-status {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
        }

        .status-item {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px 20px;
            border-radius: 10px;
            text-align: center;
        }

        .status-item.connected {
            background: rgba(76, 175, 80, 0.3);
            border: 1px solid #4caf50;
        }

        .status-item.disconnected {
            background: rgba(244, 67, 54, 0.3);
            border: 1px solid #f44336;
        }

        .voice-controls {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }

        .control-button {
            background: rgba(255, 255, 255, 0.1);
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 20px;
            border-radius: 15px;
            cursor: pointer;
            transition: all 0.3s ease;
            text-align: center;
            font-size: 1.1em;
        }

        .control-button:hover {
            background: rgba(255, 255, 255, 0.2);
            border-color: rgba(255, 255, 255, 0.5);
        }

        .control-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .control-button.active {
            background: rgba(76, 175, 80, 0.3);
            border-color: #4caf50;
        }

        .control-button.recording {
            background: rgba(244, 67, 54, 0.3);
            border-color: #f44336;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { opacity: 0.7; }
            50% { opacity: 1; }
            100% { opacity: 0.7; }
        }

        .audio-visualizer {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 30px;
            text-align: center;
        }

        .volume-bar {
            width: 100%;
            height: 10px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 5px;
            overflow: hidden;
            margin: 10px 0;
        }

        .volume-level {
            height: 100%;
            background: linear-gradient(90deg, #4caf50, #ff9800, #f44336);
            width: 0%;
            transition: width 0.1s ease;
        }

        .conversation-log {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            max-height: 300px;
            overflow-y: auto;
            margin-bottom: 20px;
        }

        .message {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 10px;
        }

        .message.user {
            background: rgba(33, 150, 243, 0.3);
            text-align: right;
        }

        .message.alice {
            background: rgba(76, 175, 80, 0.3);
        }

        .message.system {
            background: rgba(255, 193, 7, 0.3);
            font-style: italic;
            text-align: center;
        }

        .debug-info {
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            padding: 15px;
            font-family: monospace;
            font-size: 0.9em;
            max-height: 200px;
            overflow-y: auto;
        }

        .voice-settings {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .setting-group {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }

        select, input[type="range"] {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 5px;
            padding: 5px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Alice Real-time Voice</h1>
            <p>WebRTC + OpenAI Realtime API Audio Streaming</p>
        </div>

        <div class="connection-status">
            <div class="status-item" id="webrtcStatus">
                <div>üîó WebRTC</div>
                <div id="webrtcState">Disconnected</div>
            </div>
            <div class="status-item" id="realtimeStatus">
                <div>ü§ñ OpenAI Realtime</div>
                <div id="realtimeState">Disconnected</div>
            </div>
            <div class="status-item" id="audioStatus">
                <div>üéµ Audio</div>
                <div id="audioState">Ready</div>
            </div>
        </div>

        <div class="voice-settings">
            <h3>üé§ Voice Settings</h3>
            <div class="setting-group">
                <label>Alice Voice:</label>
                <select id="voiceSelect">
                    <option value="alloy">Alloy (Warm & Balanced)</option>
                    <option value="echo">Echo (Deeper Male)</option>
                    <option value="fable">Fable (British)</option>
                    <option value="nova">Nova (Energetic)</option>
                    <option value="onyx">Onyx (Rich & Deep)</option>
                    <option value="shimmer">Shimmer (Gentle)</option>
                </select>
            </div>
            <div class="setting-group">
                <label>Microphone Sensitivity:</label>
                <input type="range" id="micSensitivity" min="0.1" max="2.0" step="0.1" value="1.0">
                <span id="micSensitivityValue">1.0</span>
            </div>
            <div class="setting-group">
                <label>Speaker Volume:</label>
                <input type="range" id="speakerVolume" min="0.1" max="2.0" step="0.1" value="1.0">
                <span id="speakerVolumeValue">1.0</span>
            </div>
        </div>

        <div class="voice-controls">
            <button class="control-button" id="connectButton" onclick="connectToAlice()">
                üîå Connect to Alice
            </button>
            <button class="control-button" id="startButton" onclick="startConversation()" disabled>
                üéôÔ∏è Start Conversation  
            </button>
            <button class="control-button" id="stopButton" onclick="stopConversation()" disabled>
                ‚èπÔ∏è Stop Conversation
            </button>
            <button class="control-button" id="testButton" onclick="testMicrophone()">
                üß™ Test Microphone
            </button>
        </div>

        <div class="audio-visualizer">
            <h3>üéµ Audio Levels</h3>
            <div>Microphone Input:</div>
            <div class="volume-bar">
                <div class="volume-level" id="micLevel"></div>
            </div>
            <div>Alice Output:</div>
            <div class="volume-bar">
                <div class="volume-level" id="speakerLevel"></div>
            </div>
            <div id="audioInfo">Ready to connect...</div>
        </div>

        <div class="conversation-log" id="conversationLog">
            <div class="message system">ü§ñ Welcome! Click "Connect to Alice" to start real-time voice conversation.</div>
        </div>

        <div class="debug-info" id="debugInfo">
            <strong>Debug Log:</strong><br>
            System ready...
        </div>
    </div>

    <script>
        // Global state
        let peerConnection = null;
        let localStream = null;
        let remoteStream = null;
        let audioContext = null;
        let micAnalyzer = null;
        let isConnected = false;
        let isRecording = false;

        // Configuration
        const config = {
            voiceGatewayUrl: 'http://localhost:8001',
            iceServers: [
                { urls: 'stun:stun.l.google.com:19302' },
                { urls: 'stun:stun1.l.google.com:19302' }
            ]
        };

        // Initialize
        document.addEventListener('DOMContentLoaded', initializeApp);

        function initializeApp() {
            log('üöÄ Initializing Alice Real-time Voice Client');
            setupEventListeners();
            checkBrowserSupport();
        }

        function setupEventListeners() {
            document.getElementById('voiceSelect').addEventListener('change', updateVoiceSettings);
            document.getElementById('micSensitivity').addEventListener('input', updateMicSettings);
            document.getElementById('speakerVolume').addEventListener('input', updateSpeakerSettings);
        }

        function checkBrowserSupport() {
            if (!navigator.mediaDevices || !RTCPeerConnection) {
                logError('‚ùå Browser does not support WebRTC');
                return false;
            }
            
            log('‚úÖ Browser supports WebRTC');
            return true;
        }

        async function connectToAlice() {
            try {
                log('üîå Connecting to Alice...');
                updateConnectionStatus('webrtc', 'connecting');

                // Get user media
                localStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 24000,
                        channelCount: 1
                    },
                    video: false
                });

                log('üé§ Microphone access granted');
                setupAudioAnalysis();

                // Create peer connection
                peerConnection = new RTCPeerConnection({
                    iceServers: config.iceServers
                });

                // Setup peer connection handlers
                setupPeerConnectionHandlers();

                // Add local stream to peer connection
                localStream.getTracks().forEach(track => {
                    peerConnection.addTrack(track, localStream);
                });

                // Create and send offer
                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);

                // Send offer to Voice Gateway
                const response = await fetch(`${config.voiceGatewayUrl}/api/webrtc/offer`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        sdp: offer.sdp,
                        type: offer.type,
                        session_id: `session_${Date.now()}`
                    })
                });

                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }

                const answerData = await response.json();
                log('üì° Received WebRTC answer from Voice Gateway');

                // Set remote description
                await peerConnection.setRemoteDescription({
                    type: 'answer',
                    sdp: answerData.sdp
                });

                isConnected = true;
                updateConnectionStatus('webrtc', 'connected');
                document.getElementById('connectButton').disabled = true;
                document.getElementById('startButton').disabled = false;
                
                addMessage('system', '‚úÖ Connected to Alice! Click "Start Conversation" to begin.');

            } catch (error) {
                logError(`‚ùå Connection failed: ${error.message}`);
                updateConnectionStatus('webrtc', 'error');
            }
        }

        function setupPeerConnectionHandlers() {
            peerConnection.oniceconnectionstatechange = () => {
                log(`üßä ICE connection state: ${peerConnection.iceConnectionState}`);
                
                if (peerConnection.iceConnectionState === 'connected') {
                    updateConnectionStatus('webrtc', 'connected');
                } else if (peerConnection.iceConnectionState === 'failed') {
                    updateConnectionStatus('webrtc', 'error');
                }
            };

            peerConnection.ontrack = (event) => {
                log('üéµ Received remote audio track');
                remoteStream = event.streams[0];
                
                // Play remote audio
                const audioElement = new Audio();
                audioElement.srcObject = remoteStream;
                audioElement.play().catch(e => log(`Audio play error: ${e.message}`));
                
                updateConnectionStatus('realtime', 'connected');
            };

            peerConnection.ondatachannel = (event) => {
                const channel = event.channel;
                log(`üì° Data channel received: ${channel.label}`);
                
                channel.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    handleRealtimeMessage(data);
                };
            };
        }

        function setupAudioAnalysis() {
            audioContext = new AudioContext();
            const source = audioContext.createMediaStreamSource(localStream);
            micAnalyzer = audioContext.createAnalyser();
            micAnalyzer.fftSize = 256;
            source.connect(micAnalyzer);

            // Start audio level monitoring
            updateAudioLevels();
        }

        function updateAudioLevels() {
            if (!micAnalyzer) return;

            const bufferLength = micAnalyzer.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            micAnalyzer.getByteFrequencyData(dataArray);

            // Calculate average volume
            let sum = 0;
            for (let i = 0; i < bufferLength; i++) {
                sum += dataArray[i];
            }
            const average = sum / bufferLength;
            const volumePercent = (average / 255) * 100;

            // Update UI
            document.getElementById('micLevel').style.width = `${volumePercent}%`;

            requestAnimationFrame(updateAudioLevels);
        }

        async function startConversation() {
            try {
                log('üéôÔ∏è Starting conversation...');
                isRecording = true;
                
                document.getElementById('startButton').disabled = true;
                document.getElementById('stopButton').disabled = false;
                document.getElementById('startButton').classList.add('recording');
                
                addMessage('system', 'üé§ Listening... Speak to Alice!');
                updateConnectionStatus('audio', 'listening');

            } catch (error) {
                logError(`‚ùå Failed to start conversation: ${error.message}`);
            }
        }

        function stopConversation() {
            log('‚èπÔ∏è Stopping conversation...');
            isRecording = false;
            
            document.getElementById('startButton').disabled = false;
            document.getElementById('stopButton').disabled = true;
            document.getElementById('startButton').classList.remove('recording');
            
            addMessage('system', '‚èπÔ∏è Conversation stopped');
            updateConnectionStatus('audio', 'ready');
        }

        async function testMicrophone() {
            try {
                log('üß™ Testing microphone...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                const audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(stream);
                const analyzer = audioContext.createAnalyser();
                source.connect(analyzer);

                // Test for 3 seconds
                let testDuration = 0;
                const testInterval = setInterval(() => {
                    const bufferLength = analyzer.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    analyzer.getByteFrequencyData(dataArray);

                    const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                    log(`üé§ Mic level: ${Math.round((average/255) * 100)}%`);

                    testDuration += 100;
                    if (testDuration >= 3000) {
                        clearInterval(testInterval);
                        stream.getTracks().forEach(track => track.stop());
                        log('‚úÖ Microphone test completed');
                    }
                }, 100);

            } catch (error) {
                logError(`‚ùå Microphone test failed: ${error.message}`);
            }
        }

        function handleRealtimeMessage(data) {
            log(`üì® Realtime message: ${data.type}`);
            
            switch (data.type) {
                case 'transcript':
                    if (data.text) {
                        addMessage('user', `üé§ "${data.text}"`);
                    }
                    break;
                case 'response':
                    if (data.text) {
                        addMessage('alice', `ü§ñ ${data.text}`);
                    }
                    break;
                case 'audio_start':
                    updateConnectionStatus('audio', 'speaking');
                    break;
                case 'audio_end':
                    updateConnectionStatus('audio', 'ready');
                    break;
            }
        }

        function updateVoiceSettings() {
            const voice = document.getElementById('voiceSelect').value;
            log(`üé§ Voice changed to: ${voice}`);
            
            // Send voice update to server
            fetch(`${config.voiceGatewayUrl}/api/voice/update-voice`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ voice: voice })
            }).catch(e => log(`Voice update error: ${e.message}`));
        }

        function updateMicSettings() {
            const sensitivity = document.getElementById('micSensitivity').value;
            document.getElementById('micSensitivityValue').textContent = sensitivity;
            log(`üé§ Mic sensitivity: ${sensitivity}`);
        }

        function updateSpeakerSettings() {
            const volume = document.getElementById('speakerVolume').value;
            document.getElementById('speakerVolumeValue').textContent = volume;
            log(`üîä Speaker volume: ${volume}`);
        }

        function updateConnectionStatus(component, status) {
            const statusElement = document.getElementById(`${component}Status`);
            const stateElement = document.getElementById(`${component}State`);
            
            statusElement.className = `status-item ${status}`;
            stateElement.textContent = status.charAt(0).toUpperCase() + status.slice(1);
        }

        function addMessage(type, text) {
            const log = document.getElementById('conversationLog');
            const message = document.createElement('div');
            message.className = `message ${type}`;
            message.innerHTML = `<strong>${new Date().toLocaleTimeString()}</strong><br>${text}`;
            log.appendChild(message);
            log.scrollTop = log.scrollHeight;
        }

        function log(message) {
            console.log(message);
            const debugInfo = document.getElementById('debugInfo');
            const time = new Date().toLocaleTimeString();
            debugInfo.innerHTML += `<br>[${time}] ${message}`;
            debugInfo.scrollTop = debugInfo.scrollHeight;
        }

        function logError(message) {
            console.error(message);
            log(`‚ùå ${message}`);
            addMessage('system', `‚ùå ${message}`);
        }

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            if (localStream) {
                localStream.getTracks().forEach(track => track.stop());
            }
            if (peerConnection) {
                peerConnection.close();
            }
        });
    </script>
</body>
</html>