#!/usr/bin/env python3
"""
üéôÔ∏è LiveKit-Style Real-time Voice Engine
Implementerar verklig real-time streaming voice pipeline med:
- Stabil partial detection (250ms)
- Streaming TTS micro-chunks  
- Persistent WebSocket-session
- Sub-700ms Time-To-First-Audio
"""

import asyncio
import json
import time
import base64
import io
import wave
from datetime import datetime
from typing import Optional, Dict, Any, AsyncGenerator
from collections import deque

import requests
import httpx
from pydantic import BaseModel

# TTS imports
try:
    import piper
    PIPER_AVAILABLE = True
except ImportError:
    PIPER_AVAILABLE = False

class VoiceMessage(BaseModel):
    type: str
    transcript: Optional[str] = None
    is_final: Optional[bool] = None
    confidence: Optional[float] = None
    audio_data: Optional[str] = None  # base64
    chunk_index: Optional[int] = None
    total_chunks: Optional[int] = None
    text_fragment: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None

class StablePartialDetector:
    """
    Detekterar stabila partials enligt LiveKit-modellen:
    - H√•ller transcript stabil i 250ms ‚Üí triggar processing
    - H√∂g confidence + tillr√§cklig l√§ngd
    """
    
    def __init__(self, stability_threshold_ms: int = 250, min_confidence: float = 0.85, min_length: int = 8):
        self.stability_threshold_ms = stability_threshold_ms
        self.min_confidence = min_confidence  
        self.min_length = min_length
        
        self.last_transcript = ""
        self.last_change_time = 0
        self.is_processing = False
        
    def should_trigger(self, transcript: str, confidence: float, is_final: bool = False) -> bool:
        """
        Returnerar True om vi ska trigga processing baserat p√• stabil partial
        """
        current_time = time.time() * 1000  # ms
        
        # Alltid trigga p√• final
        if is_final:
            return True
            
        # Skippa om redan processing
        if self.is_processing:
            return False
            
        # Skippa om f√∂r kort eller l√•g confidence
        if len(transcript) < self.min_length or confidence < self.min_confidence:
            return False
            
        # Kolla stabilitet
        if transcript != self.last_transcript:
            self.last_transcript = transcript
            self.last_change_time = current_time
            return False
            
        # Stabil tillr√§ckligt l√§nge?
        time_stable = current_time - self.last_change_time
        if time_stable >= self.stability_threshold_ms:
            return True
            
        return False
    
    def set_processing(self, processing: bool):
        """Markerar om vi f√∂r n√§rvarande processar"""
        self.is_processing = processing
        
    def reset(self):
        """√Öterst√§ller detector-state"""
        self.last_transcript = ""
        self.last_change_time = 0
        self.is_processing = False

class StreamingTTSEngine:
    """
    Streaming TTS som genererar micro-chunks (3-5 ord) i realtid
    Anv√§nder amerikansk engelska r√∂st f√∂r Alice
    """
    
    def __init__(self, voice_model: str = "en_US-amy-medium"):
        self.voice_model = voice_model  # Amerikansk kvinnlig r√∂st
        self.piper_model = None
        self._initialize_piper()
        
    def _initialize_piper(self):
        """Initialiserar Piper TTS om tillg√§ngligt"""
        if not PIPER_AVAILABLE:
            print("‚ö†Ô∏è  Piper ej tillg√§ngligt - anv√§nder HTTP TTS fallback")
            return
            
        try:
            # TODO: Ladda Piper-modell f√∂r amerikansk engelska
            # self.piper_model = piper.PiperVoice.load(f"models/tts/{self.voice_model}.onnx")
            print(f"‚úÖ Piper TTS-motor initialiserad med {self.voice_model}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Kunde ej ladda Piper-modell: {e}")
            
    def split_into_chunks(self, text: str, chunk_size: int = 4) -> list[str]:
        """Delar text i sm√•delar f√∂r progressiv TTS"""
        words = text.split()
        chunks = []
        
        for i in range(0, len(words), chunk_size):
            chunk = " ".join(words[i:i + chunk_size])
            chunks.append(chunk)
            
        return chunks
        
    async def generate_streaming_audio(self, text: str) -> AsyncGenerator[bytes, None]:
        """
        Genererar audio-chunks progressivt
        F√∂rsta chunken inom ~200ms f√∂r snabb TTFA
        """
        chunks = self.split_into_chunks(text)
        
        for i, chunk in enumerate(chunks):
            start_time = time.time()
            
            try:
                if self.piper_model:
                    # Piper streaming (om tillg√§ngligt)
                    audio_bytes = await self._generate_piper_audio(chunk)
                else:
                    # HTTP TTS fallback
                    audio_bytes = await self._generate_http_tts_audio(chunk)
                
                generation_time = (time.time() - start_time) * 1000
                print(f"üéµ TTS chunk {i+1}/{len(chunks)}: '{chunk[:30]}...' ({generation_time:.0f}ms)")
                
                yield audio_bytes
                
                # Kort paus mellan chunks f√∂r naturlig rytm
                if i < len(chunks) - 1:
                    await asyncio.sleep(0.02)  # 20ms
                    
            except Exception as e:
                print(f"‚ùå TTS-fel f√∂r chunk '{chunk}': {e}")
                continue
                
    async def _generate_piper_audio(self, text: str) -> bytes:
        """Genererar audio med Piper (om tillg√§ngligt)"""
        # TODO: Implementera Piper TTS streaming
        # audio = self.piper_model.synthesize(text)
        # return audio.tobytes()
        return b""  # Placeholder
        
    async def _generate_http_tts_audio(self, text: str) -> bytes:
        """Fallback till HTTP TTS API"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "http://localhost:8000/api/tts/synthesize",
                    json={"text": text, "voice": self.voice_model},
                    timeout=5.0
                )
                
                if response.status_code == 200:
                    # TTS API returnerar JSON med base64 audio_data
                    data = response.json()
                    if data.get("success") and "audio_data" in data:
                        # Avkoda base64 f√∂r att f√• r√• audio bytes
                        return base64.b64decode(data["audio_data"])
                    else:
                        print(f"‚ö†Ô∏è  TTS API fel: {data}")
                        return b""
                else:
                    print(f"‚ö†Ô∏è  TTS API fel: {response.status_code}")
                    return b""
                    
        except Exception as e:
            print(f"‚ùå HTTP TTS fel: {e}")
            return b""

class RealtimeVoiceEngine:
    """
    Huvudmotor f√∂r real-time voice processing
    Hanterar persistent session, stabil partial detection och streaming TTS
    """
    
    def __init__(self):
        self.partial_detector = StablePartialDetector()
        self.tts_engine = StreamingTTSEngine()
        self.session_start_time = time.time()
        self.metrics = {
            'total_requests': 0,
            'avg_ttfa_ms': 0,
            'partial_triggers': 0,
            'final_triggers': 0
        }
        
        # Pre-warm Ollama connection
        asyncio.create_task(self._prewarm_llm())
        
    async def _prewarm_llm(self):
        """Pre-warmar LLM-anslutning f√∂r snabbare svar"""
        try:
            async with httpx.AsyncClient() as client:
                await client.post(
                    "http://localhost:11434/api/generate",
                    json={
                        "model": "gpt-oss:20b", 
                        "prompt": "test",
                        "options": {"num_predict": 1}
                    },
                    timeout=10.0
                )
            print("üî• LLM pre-warmed")
        except Exception as e:
            print(f"‚ö†Ô∏è  LLM pre-warm fel: {e}")
            
    async def process_voice_input(self, transcript: str, confidence: float, is_final: bool = False) -> AsyncGenerator[VoiceMessage, None]:
        """
        Huvudfunktion f√∂r voice processing
        Returnerar streaming response med audio chunks
        """
        # Kolla om vi ska trigga processing
        should_process = self.partial_detector.should_trigger(transcript, confidence, is_final)
        
        if not should_process:
            return
            
        print(f"üéØ Triggar processing: '{transcript}' (confidence: {confidence:.2f}, final: {is_final})")
        
        # Markera som processing
        self.partial_detector.set_processing(True)
        start_time = time.time()
        
        try:
            # Skicka processing_started event
            yield VoiceMessage(
                type="processing_started",
                transcript=transcript,
                metadata={
                    'trigger_type': 'final' if is_final else 'stable_partial',
                    'confidence': confidence
                }
            )
            
            # F√• LLM-respons (anv√§nd fast path f√∂r enkla fr√•gor)
            response_text = await self._get_llm_response(transcript)
            
            if not response_text:
                yield VoiceMessage(type="error", metadata={'error': 'Inget svar fr√•n LLM'})
                return
                
            print(f"üß† LLM svar: '{response_text[:50]}...'")
            
            # Streama TTS-audio
            chunk_count = 0
            async for audio_chunk in self.tts_engine.generate_streaming_audio(response_text):
                if audio_chunk:
                    chunk_count += 1
                    
                    # F√∂rsta chunk = TTFA-metrik
                    if chunk_count == 1:
                        ttfa_ms = (time.time() - start_time) * 1000
                        self.metrics['avg_ttfa_ms'] = ttfa_ms
                        print(f"‚ö° TTFA: {ttfa_ms:.0f}ms")
                    
                    # Skicka audio chunk
                    yield VoiceMessage(
                        type="audio_chunk",
                        audio_data=base64.b64encode(audio_chunk).decode(),
                        chunk_index=chunk_count,
                        metadata={'ttfa_ms': ttfa_ms if chunk_count == 1 else None}
                    )
                    
            # Slutligt meddelande
            yield VoiceMessage(
                type="response_complete",
                transcript=response_text,
                metadata={
                    'total_chunks': chunk_count,
                    'total_time_ms': (time.time() - start_time) * 1000
                }
            )
            
            # Uppdatera metrics
            self.metrics['total_requests'] += 1
            if is_final:
                self.metrics['final_triggers'] += 1
            else:
                self.metrics['partial_triggers'] += 1
                
        except Exception as e:
            print(f"‚ùå Voice processing fel: {e}")
            yield VoiceMessage(type="error", metadata={'error': str(e)})
            
        finally:
            # Frig√∂r processing-lock
            self.partial_detector.set_processing(False)
            
    async def _get_llm_response(self, prompt: str) -> str:
        """
        F√• LLM-respons med smart routing (fast path f√∂r enkla fr√•gor)
        """
        # Simple commands som kan f√• snabba svar
        fast_path_keywords = ['v√§der', 'tid', 'datum', 'hej', 'tack', 'vad', 'n√§r']
        is_fast_path = any(keyword in prompt.lower() for keyword in fast_path_keywords)
        
        try:
            if is_fast_path and len(prompt) < 50:
                # Fast path: OpenAI f√∂r snabba svar
                return await self._get_openai_response(prompt)
            else:
                # Think path: Ollama f√∂r komplexa svar
                return await self._get_ollama_response(prompt)
                
        except Exception as e:
            print(f"‚ö†Ô∏è  LLM-fel: {e}")
            return "Urs√§kta, jag hade problem att processa din fr√•ga."
            
    async def _get_ollama_response(self, prompt: str) -> str:
        """Ollama-respons f√∂r komplexa queries"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "http://localhost:11434/api/generate",
                    json={
                        "model": "gpt-oss:20b",
                        "prompt": f"You are Alice, a Swedish AI assistant. Always respond in English, even when the user speaks Swedish. User said: {prompt}. Respond briefly in English:",
                        "stream": False,
                        "options": {
                            "temperature": 0.3,
                            "num_predict": 100,  # Begr√§nsa svar-l√§ngd f√∂r snabbhet
                            "top_p": 0.9
                        }
                    },
                    timeout=15.0
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result.get('response', '').strip()
                    
        except Exception as e:
            print(f"‚ùå Ollama-fel: {e}")
            raise
            
    async def _get_openai_response(self, prompt: str) -> str:
        """OpenAI-respons f√∂r snabba queries"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={"Authorization": f"Bearer {self._get_openai_key()}"},
                    json={
                        "model": "gpt-4o-mini",
                        "messages": [
                            {"role": "system", "content": "You are Alice, a Swedish AI assistant. Always respond in English, even if the user speaks Swedish. Keep responses short and natural."},
                            {"role": "user", "content": prompt}
                        ],
                        "max_tokens": 80,
                        "temperature": 0.2
                    },
                    timeout=5.0
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content'].strip()
                    
        except Exception as e:
            print(f"‚ùå OpenAI-fel: {e}")
            raise
            
    def _get_openai_key(self) -> str:
        """H√§mta OpenAI API key fr√•n milj√∂variabel"""
        import os
        return os.getenv('OPENAI_API_KEY', '')
        
    def get_metrics(self) -> dict:
        """Returnera aktuella performance-metrics"""
        uptime = time.time() - self.session_start_time
        return {
            **self.metrics,
            'uptime_seconds': uptime,
            'session_start': datetime.fromtimestamp(self.session_start_time).isoformat()
        }
        
    def reset_session(self):
        """√Öterst√§ll session f√∂r ny anv√§ndare/konversation"""
        self.partial_detector.reset()
        self.session_start_time = time.time()
        print("üîÑ Voice session reset")

# Singleton instance f√∂r global anv√§ndning
voice_engine = RealtimeVoiceEngine()

async def handle_voice_message(message: dict) -> AsyncGenerator[dict, None]:
    """
    Wrapper-funktion f√∂r att hantera voice messages fr√•n WebSocket
    """
    try:
        # Parse inkommande meddelande
        msg_type = message.get('type', '')
        
        if msg_type == 'partial_transcript':
            transcript = message.get('transcript', '')
            confidence = message.get('confidence', 0.0)
            is_final = message.get('is_final', False)
            
            # Processa med voice engine
            async for response in voice_engine.process_voice_input(transcript, confidence, is_final):
                yield response.dict()
                
        elif msg_type == 'get_metrics':
            yield {
                'type': 'metrics',
                'data': voice_engine.get_metrics()
            }
            
        elif msg_type == 'reset_session':
            voice_engine.reset_session()
            yield {
                'type': 'session_reset',
                'status': 'ok'
            }
            
    except Exception as e:
        yield {
            'type': 'error', 
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }