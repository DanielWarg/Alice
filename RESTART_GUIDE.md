# Alice System Restart Guide
*Skapad: 2025-08-28 efter minnesoptimering*

## üöÄ Snabb uppstart efter restart

### 1. Kontrollera att alla tj√§nster √§r stoppade
```bash
# Kontrollera att inga processer k√∂r
pkill -f "ollama"
pkill -f "node"
pkill -f "python"
```

### 2. Starta Alice System (Optimerad version)

**Terminal 1 - Backend:**
```bash
cd /Users/evil/Desktop/EVIL/PROJECT/Alice/server
source .venv/bin/activate
python app_minimal.py
```

**Terminal 2 - Frontend:**
```bash
cd /Users/evil/Desktop/EVIL/PROJECT/Alice/web
npm run dev
```

### 3. Testa systemet
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000/health
- **LLM Status**: http://localhost:8000/api/v1/llm/status

## ‚öôÔ∏è Aktuella konfigurationer (efter optimering)

### LLM Setup
- **Primary Model**: `llama3:8b` (4.6GB, s√§ker minnesanv√§ndning)
- **Fallback Model**: `openai:gpt-4o-mini`
- **Keep-alive**: 10 minuter (ist√§llet f√∂r 30m)
- **Model warmer**: 8 minuters intervall

### Fil√§ndringar gjorda:
1. `server/llm/ollama.py`: 
   - Bytt fr√•n `gpt-oss:20b` ‚Üí `llama3:8b`
   - Keep-alive: `30m` ‚Üí `10m`
2. `server/model_warmer.py`:
   - Default modell: `llama3:8b`
   - Intervall: `20m` ‚Üí `8m`

### Milj√∂variabler (om du vill √§ndra):
```bash
export LLM_MODEL="llama3:8b"           # Eller phi3:mini (2GB) / qwen2.5-coder:1.5b (1GB)  
export LLM_KEEP_ALIVE="10m"            # Minnesv√§nligare
export LLM_HEALTH_TIMEOUT_MS="2000"    # Lite mer tid f√∂r health checks
```

## üîç Fels√∂kning efter restart

### Om Ollama inte startar:
```bash
# Starta Ollama manuellt
ollama serve &

# Kontrollera att modeller finns
curl http://localhost:11434/api/tags
```

### Om modeller saknas:
```bash
# Ladda ner rekommenderade modeller (s√§kra alternativ till gpt-oss:20b)
ollama pull llama3:8b        # 4.6GB, b√§sta balans
ollama pull phi3:mini        # 2.1GB, snabb
ollama pull qwen2.5-coder:1.5b  # 1GB, extremt snabb
```

### Om frontend inte hittar backend:
- Kontrollera att backend k√∂rs p√• port 8000
- Kolla CORS-inst√§llningar i `app_minimal.py`

## üìä Minnestests (n√§r systemet √§r ig√•ng)

### Testa minnesanv√§ndning:
```bash
# K√∂r performance test (5 minuter, 10s intervall)
cd /Users/evil/Desktop/EVIL/PROJECT/Alice/server
python performance_test.py 10 10

# √ñvervaka systemresurser (5 minuter)  
python system_monitor.py 5
```

### S√§kra modeller att testa:
1. **llama3:8b** - B√§sta kvalitet vs minnesanv√§ndning
2. **phi3:mini** - Snabbast, minst minne
3. **qwen2.5-coder:1.5b** - Extremt snabb f√∂r kodning

## ‚ö†Ô∏è Vad vi l√§rde oss fr√•n gpt-oss:20b

**Undvik:**
- gpt-oss:20b (20B parametrar = 14GB RAM konstant)
- Keep-alive > 15 minuter p√• stora modeller
- Model warming utan memory monitoring

**Anv√§nd ist√§llet:**
- Modeller < 10B parametrar f√∂r daglig anv√§ndning
- Keep-alive 5-10 minuter
- System monitoring under f√∂rsta timmarna

## üéØ N√§sta steg efter restart

1. **Testa grundfunktioner** - Chat via HUD
2. **Verifiera prestanda** - K√∂r performance_test.py
3. **√ñvervaka minne** - system_monitor.py f√∂rsta 30 min
4. **Optimera vidare** - Justera keep-alive baserat p√• anv√§ndning

---
**Anteckning**: Alla performance-script finns i `server/` mappen och √§r redo att k√∂ra.