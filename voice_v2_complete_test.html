<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice v2 Complete - ASR + TTS</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 30px;
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .voice-section {
            margin: 20px 0;
            padding: 25px;
            background: rgba(255, 255, 255, 0.08);
            border-radius: 15px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .mic-button {
            background: linear-gradient(45deg, #ff4757, #ff6348);
            border: none;
            color: white;
            padding: 25px;
            border-radius: 50%;
            font-size: 32px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 20px;
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
            width: 100px;
            height: 100px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .mic-button:hover {
            transform: translateY(-3px) scale(1.05);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.4);
        }
        
        .mic-button.listening {
            background: linear-gradient(45deg, #e74c3c, #c0392b);
            animation: pulse 1.5s infinite;
        }
        
        .mic-button.processing {
            background: linear-gradient(45deg, #f39c12, #e67e22);
            animation: spin 2s linear infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        @keyframes spin {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }
        
        .status-bar {
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: rgba(0, 0, 0, 0.2);
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
        }
        
        .metric {
            text-align: center;
            padding: 10px;
        }
        
        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #3498db;
        }
        
        .metric-label {
            font-size: 12px;
            opacity: 0.8;
        }
        
        .transcript {
            background: rgba(0, 0, 0, 0.2);
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 18px;
            min-height: 60px;
            border-left: 4px solid #3498db;
        }
        
        .response {
            background: rgba(46, 204, 113, 0.2);
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            font-size: 18px;
            min-height: 60px;
            border-left: 4px solid #2ecc71;
        }
        
        .log {
            max-height: 200px;
            overflow-y: auto;
            background: rgba(0, 0, 0, 0.3);
            padding: 15px;
            border-radius: 10px;
            font-family: monospace;
            font-size: 12px;
        }
        
        .center {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
        }
        
        audio {
            width: 100%;
            margin: 15px 0;
        }
        
        .slo-indicator {
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-left: 8px;
        }
        
        .slo-pass { background-color: #2ecc71; }
        .slo-warn { background-color: #f39c12; }
        .slo-fail { background-color: #e74c3c; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Voice v2 Complete</h1>
        <p style="text-align: center; opacity: 0.8;">ASR + Brain + TTS Pipeline</p>
        
        <div class="voice-section">
            <div class="center">
                <button class="mic-button" id="micButton" onclick="toggleVoiceRecording()">
                    üé§
                </button>
                <p id="micStatus">Hold to talk (ASR WebSocket)</p>
            </div>
            
            <div class="status-bar">
                <div class="metric">
                    <div class="metric-value" id="asrLatency">-</div>
                    <div class="metric-label">ASR (ms) <span id="asrSLO" class="slo-indicator"></span></div>
                </div>
                <div class="metric">
                    <div class="metric-value" id="brainLatency">-</div>
                    <div class="metric-label">Brain (ms)</div>
                </div>
                <div class="metric">
                    <div class="metric-value" id="ttsLatency">-</div>
                    <div class="metric-label">TTS (ms) <span id="ttsSLO" class="slo-indicator"></span></div>
                </div>
                <div class="metric">
                    <div class="metric-value" id="e2eLatency">-</div>
                    <div class="metric-label">E2E (ms) <span id="e2eSLO" class="slo-indicator"></span></div>
                </div>
            </div>
        </div>

        <div class="voice-section">
            <h3>üéØ Conversation</h3>
            <div class="transcript" id="transcript">
                Your speech will appear here...
            </div>
            
            <div class="response" id="response">
                Alice's response will appear here...
            </div>
            
            <audio id="responseAudio" controls preload="none">
                Your browser does not support audio.
            </audio>
        </div>

        <div class="voice-section">
            <h3>üìä System Log</h3>
            <div id="systemLog" class="log">
                Voice v2 Complete system starting...<br>
            </div>
        </div>
    </div>

    <script>
        const BASE_URL = 'http://localhost:8000';
        const WS_URL = 'ws://localhost:8000/ws/asr';
        
        let asrWebSocket = null;
        let mediaRecorder = null;
        let audioStream = null;
        let isRecording = false;
        let conversationStartTime = null;
        let asrStartTime = null;
        
        function log(message) {
            const timestamp = new Date().toLocaleTimeString();
            document.getElementById('systemLog').innerHTML += `[${timestamp}] ${message}<br>`;
            document.getElementById('systemLog').scrollTop = document.getElementById('systemLog').scrollHeight;
        }
        
        function updateSLO(elementId, latency, target) {
            const indicator = document.getElementById(elementId);
            if (latency <= target * 0.8) {
                indicator.className = 'slo-indicator slo-pass';
            } else if (latency <= target) {
                indicator.className = 'slo-indicator slo-warn'; 
            } else {
                indicator.className = 'slo-indicator slo-fail';
            }
        }
        
        function updateMetrics(asr_ms, brain_ms, tts_ms, e2e_ms) {
            document.getElementById('asrLatency').textContent = asr_ms || '-';
            document.getElementById('brainLatency').textContent = brain_ms || '-';
            document.getElementById('ttsLatency').textContent = tts_ms || '-';
            document.getElementById('e2eLatency').textContent = e2e_ms || '-';
            
            // SLO targets: ASR ‚â§ 350ms, TTS ‚â§ 800ms, E2E ‚â§ 1200ms
            if (asr_ms) updateSLO('asrSLO', asr_ms, 350);
            if (tts_ms) updateSLO('ttsSLO', tts_ms, 800);
            if (e2e_ms) updateSLO('e2eSLO', e2e_ms, 1200);
        }
        
        async function initASRWebSocket() {
            try {
                asrWebSocket = new WebSocket(WS_URL);
                
                asrWebSocket.onopen = function() {
                    log('‚úÖ ASR WebSocket connected');
                    document.getElementById('micStatus').textContent = 'Ready - Hold microphone to talk';
                };
                
                asrWebSocket.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    handleASREvent(data);
                };
                
                asrWebSocket.onclose = function() {
                    log('‚ùå ASR WebSocket disconnected');
                    document.getElementById('micStatus').textContent = 'WebSocket disconnected';
                };
                
                asrWebSocket.onerror = function(error) {
                    log(`‚ùå ASR WebSocket error: ${error}`);
                };
                
            } catch (error) {
                log(`‚ùå Failed to connect ASR WebSocket: ${error}`);
            }
        }
        
        function handleASREvent(event) {
            const eventType = event.event;
            log(`üé§ ASR Event: ${eventType}`);
            
            switch (eventType) {
                case 'session_start':
                    log(`üöÄ ASR Session: ${event.asr_engine} (${event.language})`);
                    break;
                    
                case 'speech_start':
                    log('üó£Ô∏è Speech detected, starting transcription...');
                    asrStartTime = performance.now();
                    break;
                    
                case 'partial':
                    document.getElementById('transcript').textContent = `"${event.text}..." (partial)`;
                    break;
                    
                case 'final':
                    const asrLatency = Math.round(event.asr_latency_ms);
                    document.getElementById('transcript').textContent = `"${event.text}" (${event.confidence.toFixed(2)})`;
                    log(`‚úÖ ASR Final: "${event.text}" (${asrLatency}ms, conf: ${event.confidence.toFixed(2)})`);
                    updateMetrics(asrLatency, null, null, null);
                    
                    // Send to brain for processing
                    processBrainResponse(event.text);
                    break;
                    
                case 'error':
                    log(`‚ùå ASR Error: ${event.message}`);
                    break;
            }
        }
        
        async function processBrainResponse(userText) {
            const brainStartTime = performance.now();
            log(`üß† Processing: "${userText}"`);
            
            try {
                const response = await fetch(`${BASE_URL}/api/llm/complete`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        messages: [
                            {
                                role: 'system',
                                content: 'Du √§r Alice, en hj√§lpsam AI-assistent. Svara naturligt p√• svenska. H√•ll svaren korta och konversationella.'
                            },
                            {
                                role: 'user',
                                content: userText
                            }
                        ],
                        model: 'gpt-oss:20b',
                        max_tokens: 100,
                        temperature: 0.7
                    })
                });
                
                if (!response.ok) throw new Error(`HTTP ${response.status}`);
                
                const data = await response.json();
                const brainLatency = Math.round(performance.now() - brainStartTime);
                const aliceResponse = data.choices?.[0]?.message?.content || 'F√∂rl√•t, jag kunde inte bearbeta din beg√§ran.';
                
                document.getElementById('response').textContent = aliceResponse;
                log(`ü§ñ Brain response (${brainLatency}ms): "${aliceResponse}"`);
                updateMetrics(null, brainLatency, null, null);
                
                // Convert to speech
                await convertToSpeech(aliceResponse);
                
            } catch (error) {
                log(`‚ùå Brain processing failed: ${error}`);
                document.getElementById('response').textContent = `Brain error: ${error.message}`;
            }
        }
        
        async function convertToSpeech(text) {
            const ttsStartTime = performance.now();
            log(`üîä TTS: "${text.substring(0, 30)}..."`);
            
            try {
                const response = await fetch(`${BASE_URL}/api/tts/`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        text: text,
                        voice: 'nova',
                        rate: 1.0
                    })
                });
                
                if (!response.ok) throw new Error(`HTTP ${response.status}`);
                
                const data = await response.json();
                const ttsLatency = Math.round(data.processing_time_ms);
                const totalE2E = conversationStartTime ? Math.round(performance.now() - conversationStartTime) : null;
                
                log(`‚úÖ TTS complete (${ttsLatency}ms): ${data.cached ? 'cached' : 'generated'}, SLO: ${data.slo_verdict}`);
                updateMetrics(null, null, ttsLatency, totalE2E);
                
                // Play audio
                const audioPlayer = document.getElementById('responseAudio');
                audioPlayer.src = `${BASE_URL}${data.url}`;
                audioPlayer.load();
                
                try {
                    await audioPlayer.play();
                    log('üéµ Playing Alice response');
                } catch {
                    log('‚ÑπÔ∏è Auto-play blocked - click play button');
                }
                
            } catch (error) {
                log(`‚ùå TTS failed: ${error}`);
            }
        }
        
        async function initMicrophone() {
            try {
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                log('‚úÖ Microphone access granted');
                return true;
                
            } catch (error) {
                log(`‚ùå Microphone access denied: ${error}`);
                return false;
            }
        }
        
        async function toggleVoiceRecording() {
            if (!asrWebSocket || asrWebSocket.readyState !== WebSocket.OPEN) {
                log('‚ùå ASR WebSocket not connected');
                return;
            }
            
            if (!isRecording) {
                // Start recording
                if (!audioStream && !(await initMicrophone())) {
                    return;
                }
                
                conversationStartTime = performance.now();
                isRecording = true;
                
                document.getElementById('micButton').classList.add('listening');
                document.getElementById('micStatus').textContent = 'Listening... Click to stop';
                document.getElementById('transcript').textContent = 'Listening for speech...';
                
                // Start MediaRecorder
                mediaRecorder = new MediaRecorder(audioStream);
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        sendAudioToASR(event.data);
                    }
                };
                
                mediaRecorder.start(100); // Send data every 100ms
                
                // Tell ASR to start listening
                asrWebSocket.send(JSON.stringify({
                    type: 'start_listening'
                }));
                
                log('üé§ Voice recording started');
                
            } else {
                // Stop recording
                isRecording = false;
                
                document.getElementById('micButton').classList.remove('listening');
                document.getElementById('micButton').classList.add('processing');
                document.getElementById('micStatus').textContent = 'Processing...';
                
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                }
                
                // Tell ASR to stop listening
                asrWebSocket.send(JSON.stringify({
                    type: 'stop_listening'
                }));
                
                log('üé§ Voice recording stopped');
                
                setTimeout(() => {
                    document.getElementById('micButton').classList.remove('processing');
                    document.getElementById('micStatus').textContent = 'Ready - Click to talk';
                }, 2000);
            }
        }
        
        function sendAudioToASR(audioBlob) {
            const reader = new FileReader();
            reader.onload = function() {
                const audioBuffer = reader.result;
                const base64Audio = btoa(String.fromCharCode(...new Uint8Array(audioBuffer)));
                
                asrWebSocket.send(JSON.stringify({
                    type: 'audio',
                    audio: base64Audio
                }));
            };
            reader.readAsArrayBuffer(audioBlob);
        }
        
        // Initialize system
        document.addEventListener('DOMContentLoaded', async function() {
            log('üöÄ Voice v2 Complete system starting...');
            
            // Check backend health
            try {
                const [healthResp, asrResp] = await Promise.all([
                    fetch(`${BASE_URL}/health`),
                    fetch(`${BASE_URL}/api/asr/health`)
                ]);
                
                if (healthResp.ok && asrResp.ok) {
                    log('‚úÖ Backend services healthy');
                    await initASRWebSocket();
                } else {
                    log('‚ùå Backend services unavailable');
                }
                
            } catch (error) {
                log(`‚ùå Backend connection failed: ${error}`);
            }
        });
        
        // Keyboard shortcuts
        document.addEventListener('keydown', function(event) {
            if (event.code === 'Space' && event.ctrlKey) {
                event.preventDefault();
                toggleVoiceRecording();
            }
        });
    </script>
</body>
</html>