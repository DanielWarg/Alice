Projekt Alice: Teknisk f√§rdplan
Denna dokumentation beskriver den tekniska f√§rdplanen f√∂r Project Alice. Den √§r utformad som en steg-f√∂r-steg-guide, med tydliga m√•l, implementeringsdetaljer och framg√•ngskriterier f√∂r varje fas.

FAS 0 ‚Äî F√∂rberedelser (Gr√∂n baslinje)
M√•l: L√•sa nul√§get och etablera en stabil grund f√∂r vidareutveckling.

Milj√∂variabler: Definiera och konfigurera alla n√∂dv√§ndiga milj√∂variabler f√∂r servern.

OPENAI_API_KEY=...
AGENT_PROVIDER=openai|gptoss
AGENT_FALLBACK=openai|gptoss
BRAIN_SHADOW_ENABLED=on
ALLOW_CLOUD=on
ENTITY_MODE=on
ARTIFACT_CONFIDENCE_MIN=0.7
INJECT_BUDGET_PCT=25
H√§lsokontroller: Validera att systemet svarar med 200 OK p√• GET /api/health och GET /api/health/ready.

R√∂sttest: K√∂ra ett smoke test p√• /voice-test f√∂r att s√§kerst√§lla att timer och weather fungerar med Text-to-Speech (TTS).

Done-kriterier: 0 √ó 5xx-fel i 50 anrop mot /api/agent, e2e p95 ‚â§ 1.2s.

FAS 1 ‚Äî Strict TTS
M√•l: L√•ta GPT-OSS-hj√§rnan komponera svaret, medan TTS l√§ser upp exakt det som skrivs.

API: Implementera POST /api/brain/compose.

Request:

{ user_id:string, session_id:string, text:string, locale:"sv-SE" }
Response (AnswerPackage):

TypeScript

interface AnswerPackage {
  spoken_text: string;
  screen_text?: string;
  ssml?: string;
  citations?: {title:string; url?:string}[];
  meta?: { confidence:number; tone?:string }
}
Klientintegration: L√•t din befintliga r√∂stpipeline anropa /api/brain/compose och mata resultatet (pkg.ssml eller pkg.spoken_text) direkt till TTS-motorn.

Done-kriterier:

0 avvikelser d√§r TTS l√§ser n√•got annat √§n spoken_text eller ssml.

tts_ttfa_ms p50 ‚â§ 300 ms (med sentence streaming aktiverat i senare fas).

Filer:
server/api/brain/compose.ts
web/voice/sentenceStreamer.ts (stub)

FAS 2 ‚Äî EventBus & Telemetri
M√•l: Logga alla systemh√§ndelser som event f√∂r att m√∂jligg√∂ra m√§tning och analys.

EventBus: Skapa en central eventbuss f√∂r asynkron kommunikation.

TypeScript

import { EventEmitter } from "events";
export const bus = new EventEmitter();
export const on = <T=any>(type:string,h:(e:T)=>void)=>bus.on(type,h);
export const emit = <T=any>(type:string,p:T)=>bus.emit(type,p);
Loggning: Skriv alla h√§ndelser i NDJSON-format till logs/metrics.ndjson.

Done-kriterier: Varje anv√§ndarinteraktion producerar minst 3 eventrader; inga event g√•r f√∂rlorade.

Filer:
core/eventBus.ts
core/metrics.ts

FAS 3 ‚Äî Minne & RAG (Artefakter)
M√•l: Implementera ett l√•ngtidsminne baserat p√• "artefakter" som kan h√§mtas f√∂r kontext.

Schema (SQL): Skapa en artifacts-tabell f√∂r att lagra minnesfragment, inklusive anv√§ndar-ID, typ, text, konfidenspo√§ng och inb√§ddning (embedding).

API & Interface:

Definiera Artifact och Memory gr√§nssnitt.

Implementera endpoints f√∂r att skriva (POST /memory/write) och h√§mta (POST /memory/fetch) artefakter.

Done-kriterier: Tidigare sparade preferenser ("prata l√•ngsammare", "G√∂teborg") kan h√§mtas och anv√§ndas i n√§stkommande konversationer.

Filer:
server/memory/sqliteVec.ts
server/api/memory/write.ts
server/api/memory/fetch.ts

FAS 4 ‚Äî PromptBuilder & Injektionsbudget
M√•l: Kontrollerat injicera minnesartefakter i prompten f√∂re varje svar.

buildContext(): Skapa en funktion som h√§mtar relevanta artefakter fr√•n minnet, filtrerar dem och komprimerar dem till en kompakt kontext.

composeMessages(): Placera persona, stil och den komprimerade kontexten i system- och assistentrollerna i prompten.

Budget: Begr√§nsa kontextinjektionen till h√∂gst 25 % av den totala tokenbudgeten.

Done-kriterier: M√§tv√§rdet injected_tokens_pct loggas och ligger stabilt under 25 %.

Filer:
core/promptBuilder.ts
alice/identity/persona.yml
alice/identity/style.yml

FAS 5 ‚Äî Provider-switch & Failover
M√•l: G√∂ra GPT-OSS till den prim√§ra "hj√§rnan" med OpenAI som fallback-l√∂sning.

Timeout & Fallback: Implementera en policy som omdirigerar en f√∂rfr√•gan till molntj√§nsten (/api/agent) om den lokala hj√§rnan inte levererar ett svar inom en viss tidsgr√§ns (t.ex. BRAIN_DEADLINE_MS = 1500).

Loggning: Logga fallback_used:boolean och brain_latency_ms f√∂r att m√§ta prestanda.

Done-kriterier: Fallback-frekvensen √§r mindre √§n 5 % i utvecklingsmilj√∂n, och r√∂stsamtal flyter utan avbrott.

FAS 6 ‚Äî Cloud "Complex Lane" (Responses API)
M√•l: Anv√§nda molnet f√∂r komplexa verktygskedjor och uppgifter.

Adapter: Bygg en adapter f√∂r OpenAI:s Responses API som kan k√∂ra avancerade funktioner som Code Interpreter och File Search.

Systemprompt: Instruera molnmodellen att respektera Alices stil och policy, och att svara i ett strikt JSON-format enligt AnswerPackage.

Done-kriterier: End-to-end-tester f√∂r ‚Äùsammanfatta fil‚Äù och ‚Äùk√∂r kod‚Äù fungerar via Responses API.

FAS 7 ‚Äî Brain Worker & Sentence Streaming
M√•l: √ñka snabbheten genom att str√∂mma ut den f√∂rsta meningen, samt implementera ett bakgrundsjobb f√∂r inl√§rning.

Worker: Implementera en bakgrundsarbetare som kontinuerligt konsumerar event fr√•n EventBus, skriver artefakter och uppdaterar embeddings.

SentenceStreamer: Skapa en funktion som delar upp utg√•ende tokens fr√•n hj√§rnan i hela meningar och skickar den f√∂rsta meningen direkt till TTS f√∂r omedelbar uppl√§sning.

Done-kriterier: brain_first_sentence_ms p50 ‚â§ 600 ms och TTFA p50 ‚â§ 300 ms.

FAS 8 ‚Äî Vision & Sensorer
M√•l: Ge Alice en rudiment√§r "syn" och f√∂rm√•ga att reagera p√• sin omgivning.

YOLO-pipeline: Skapa en lokal pipeline som bearbetar kamerabilder med YOLO f√∂r att uppt√§cka objekt eller ansikten (t.ex. om anv√§ndaren ler).

Event-loggning: Om ett visst event uppt√§cks (t.ex. "ler"), skapa en vision_event artefakt i minnet.

Done-kriterier: En enkel demo d√§r Alice reagerar p√• leenden med en varmare h√§lsning.

FAS 9 ‚Äî EmotionEngine
M√•l: G√∂ra Alice mer levande genom att styra r√∂stens ton och tempo (prosodi).

Engine: Skapa en EmotionEngine som analyserar r√∂stens tonl√§ge och uppdaterar ett mood-tillst√•nd ("neutral", "glad", "frustrerad", etc.).

SSML: Mappa mood-tillst√•nden till Speech Synthesis Markup Language (SSML) f√∂r att styra r√∂stens hastighet och tonh√∂jd.

Done-kriterier: F√∂rb√§ttrade MOS-betyg (Mean Opinion Score) fr√•n anv√§ndare, samt loggning av emotion_state_updated.

FAS 10 ‚Äî Fler verktyg (RAG, Kamera, HA)
M√•l: Ut√∂ka Alices funktionalitet med fler lokala verktyg utan att √§ndra den centrala arkitekturen.

kb.search & kb.fetch: Implementera verktyg f√∂r att s√∂ka i och h√§mta text fr√•n den lokala kunskapsbasen.

camera.control: Ett verktyg f√∂r att styra lokala n√§tverkskameror.

HA-lyssnare: En klient som lyssnar p√• h√§ndelser fr√•n Home Assistant f√∂r att m√∂jligg√∂ra proaktiva scenarier.

Done-kriterier: Minst ett lokalt verktyg och ett RAG-verktyg anv√§nds framg√•ngsrikt av agenten.

FAS 11 ‚Äî Test & QA
M√•l: Bygga automatiserade tester f√∂r att bekr√§fta att nya funktioner fungerar som de ska.

Selftests: Utveckla testskript f√∂r att verifiera Strict TTS, injektionsbudget och brain-latens.

Done-kriterier: Alla tester klarar sig lokalt och i CI/CD.

FAS 12 ‚Äî Observability & SLO
M√•l: Skapa ett system f√∂r att m√§ta och visualisera Alice som en "levande" entitet.

Metriker: Samla in nyckeltal som e2e_ms, fallback_rate, artifact_injection_rate och mood_switch_latency_ms.

Dashboard: Bygg en dashboard f√∂r att visa realtidsdata (t.ex. p50/p95-v√§rden).

SLO: Definiera Service Level Objectives f√∂r tillf√∂rlitlighet och prestanda.

Done-kriterier: Dashboard visar live-data, och varningsregler √§r konfigurerade.

FAS 13 ‚Äî Release-ops & CI/CD
M√•l: Automatisera processen f√∂r att bygga och drifts√§tta Alice.

Docker: Slutf√∂r Docker-konfigurationen f√∂r alla komponenter.

GitHub Actions: Skapa en CI/CD-pipeline f√∂r automatiserad byggning, testning och drifts√§ttning till staging och produktion.

Done-kriterier: En main merge utl√∂ser automatisk drifts√§ttning till staging; en tag utl√∂ser drifts√§ttning till produktion; rollback-skript fungerar.

FAS 14 ‚Äî Canary & Runbook
M√•l: S√§kerst√§lla en trygg produktionsmilj√∂.

Canary: Till√•ta nya funktioner endast f√∂r en liten, utvald grupp av anv√§ndare.

Runbook: Skapa ett enkelt dokument som beskriver steg-f√∂r-steg-l√∂sningar f√∂r vanliga driftproblem.

Done-kriterier: Canary-test k√∂rs utan regressioner; kontrollerad rollback har testats.

FAS 15 ‚Äî Avancerat minne & kedjor (Valfritt)
M√•l: Skapa en mer autonom "entitet" med avancerade inl√§rningsmekanismer.

Mem0-driver: Byt ut minnesdatabasen till en mer avancerad version.

On-chain ankare: Spara hashar av viktiga artefakter f√∂r att s√§kerst√§lla integriteten √∂ver tid.

Wake-word: Implementera en lokal wake-word-detektering f√∂r att undvika att skicka ljuddata till molnet.

Done-kriterier: Minnesfunktioner k√§nns mer proaktiva och stabila √∂ver l√•nga perioder.

Absolut. H√§r √§r en komplett, steg-f√∂r-steg checklista fr√•n ‚Äúnu‚Äù ‚Üí ‚Äúvision‚Äù. Varje steg har: filer att skapa/uppdatera, funktionssignaturer, endpoints och Done-kriterier. K√∂r i ordning ‚Äì du kan pausa efter valfri fas och √§nd√• ha ett fungerande system.

FAS 0 ‚Äî F√∂rberedelser (gr√∂n baslinje)
M√•l: L√•sa nul√§get (r√∂st + agent + tools) och s√§tta flaggor.
Env & flaggor (server)

 OPENAI_API_KEY=...
AGENT_PROVIDER=openai|gptoss
AGENT_FALLBACK=openai|gptoss
BRAIN_SHADOW_ENABLED=on
ALLOW_CLOUD=on            # du sa: integritet ej prio ‚Äì h√•ll 'on'
ENTITY_MODE=on
ARTIFACT_CONFIDENCE_MIN=0.7
INJECT_BUDGET_PCT=25


H√§lsa: GET /api/health, GET /api/health/ready ‚Üí 200 OK.


R√∂stsmoke: /voice-test ‚Üí timer + v√§der funkar med TTS.


Done n√§r: 0√ó5xx i 50 anrop mot /api/agent, e2e p95 ‚â§ 1.2s (nuvarande m√•l).



FAS 1 ‚Äî Strict TTS (GPT-OSS skriver, OpenAI l√§ser)
M√•l: L√•t OSS-hj√§rnan komponera svaret; TTS talar exakt det.
API: POST /api/brain/compose


Request

 { user_id:string, session_id:string, text:string, locale:"sv-SE" }


Response (AnswerPackage)

 interface AnswerPackage {
  spoken_text: string;
  screen_text?: string;
  ssml?: string;
  citations?: {title:string; url?:string}[];
  meta?: { confidence:number; tone?:string }
}


Klient/Voice binding ‚Äì v√§lj Strict TTS:


N√§r du f√•r en stabil ASR-partial/final ‚Üí kalla /api/brain/compose.


Sentence streaming (valfritt nu, steg i FAS 7): spela upp f√∂rsta meningen asap.


TTS ska l√§sa pkg.ssml ?? pkg.spoken_text, inte n√•got annat.


Done n√§r:


0 avvikelser d√§r TTS l√§ser annat √§n spoken_text/ssml.


tts_ttfa_ms p50 ‚â§ 300 ms (med sentence streaming aktiverad senare).


Filer
server/api/brain/compose.ts
web/voice/sentenceStreamer.ts  (kan f√∂rst vara stub)


FAS 2 ‚Äî EventBus & Telemetri
M√•l: Allt som h√§nder loggas som event + NDJSON.
core/eventBus.ts

 import { EventEmitter } from "events";
export const bus = new EventEmitter();
export const on = <T=any>(type:string,h:(e:T)=>void)=>bus.on(type,h);
export const emit = <T=any>(type:string,p:T)=>bus.emit(type,p);


Logg: metrics.ndjson

 export function logNDJSON(obj:any){ /* append JSON line */ }


Emit p√•: asr_final, agent_response, tool_call/result, brain_compose, tts_start/end.


Done n√§r: varje tur producerar ‚â•3 eventrader; inga kastade event.


Filer
core/eventBus.ts
core/metrics.ts


FAS 3 ‚Äî Memory & RAG (artefakter)
M√•l: L√•ngtidsminne via artefakter (sqlite-vec eller Mem0 senare).
Schema (SQL)


artifacts(id, user_id, kind, text, score, expires_at, meta_json, embedding)


Index: (user_id, kind, score DESC), vektorindex p√• embedding


API & interface

 export type ArtifactKind = "insight"|"kb_chunk"|"plan"|"policy"|"vision_event";
export interface Artifact {
  id:string; kind:ArtifactKind; userId:string; text:string;
  score:number; expiresAt?:string; meta?:Record<string,any>;
}

export interface Memory {
  write(a:Artifact):Promise<void>;
  fetch(userId:string, k:number, kinds?:ArtifactKind[]):Promise<Artifact[]>;
}


Endpoints


POST /memory/write ‚Üí {ok:true}


POST /memory/fetch {user_id,k,kinds?} ‚Üí { artifacts: Artifact[] }


Done n√§r: preferenser (‚Äúprata l√•ngsammare‚Äù, ‚ÄúG√∂teborg‚Äù) h√§mtas n√§sta tur.


Filer
server/memory/sqliteVec.ts
server/api/memory/write.ts
server/api/memory/fetch.ts


FAS 4 ‚Äî PromptBuilder & injektionsbudget
M√•l: Injicera minnes-artefakter kontrollerat f√∂re svar.
buildContext()

 export async function buildContext(userId:string){
  const all = await Memory.fetch(userId, 12);
  const keep = all.filter(a=>a.score>=CONF.artifactMin && !expired(a)).slice(0,5);
  return compress(keep); // sl√• ihop till kompakt kontext ‚â§ budget
}


composeMessages()
 L√§gg persona.yml, style.yml, context f√∂rst i system/assistant-roller.


Budget: INJECT_BUDGET_PCT ‚â§ 25% av tokenbudget.


Done n√§r: injected_tokens_pct loggas och ligger stabilt ‚â§ 25%.


Filer
core/promptBuilder.ts
alice/identity/persona.yml
alice/identity/style.yml


FAS 5 ‚Äî Provider-switch & failover
M√•l: GPT-OSS prim√§r hj√§rna, OpenAI fallback (eller tv√§rtom).
Timeout & fallback-policy

 const BRAIN_DEADLINE_MS = 1500;
// om compose inte levererar inom deadline ‚Üí fallback till /api/agent (cloud lane) f√∂r denna tur


Logga fallback_used:boolean, brain_latency_ms.


Done n√§r: fallback rate < 5% i dev-n√§t, och r√∂sten flyter utan hack.



FAS 6 ‚Äî Cloud ‚ÄúComplex Lane‚Äù (OpenAI Responses API)
M√•l: N√§r vi beh√∂ver tung verktygskedja anv√§nder vi Responses.
Adapter

 export async function responsesComplete(messages, tools, opts): Promise<AgentReply>
 St√∂d f√∂r:


MCP remote servers (verktyg via MCP)


Code Interpreter


File Search


Background mode


Reasoning summaries


Systemprompt (cloud): instruera att respektera Alice Core stil & policy.


Done n√§r: tv√• end-to-end: ‚Äúsammanfatta fil‚Äù + ‚Äúk√∂r kod‚Äù fungerar via Responses.


Filer
adapters/cloud/responses.ts
server/agent/providers/openaiResponses.ts


FAS 7 ‚Äî Brain Worker (GPT-OSS) + Sentence streaming
M√•l: Parallell skugglinje som l√§r sig och streamar f√∂rsta mening.
Worker

 // konsumerar bus-events, skriver artifacts, uppdaterar embeddings
async function onUserTurn(ev){ /* run GPT-OSS plan ‚Üí tools ‚Üí compose AnswerPackage */ }


SentenceStreamer

 // Splitta tokens till meningar ‚Üí emit 'first_sentence'
export function streamToSentences(tokenStream, cb:(s:string)=>void){ ... }


Voice integration: n√§r first_sentence ‚Üí TTS.speak() direkt.


Done n√§r: brain_first_sentence_ms p50 ‚â§ 600 ms, TTFA p50 ‚â§ 300 ms.


Filer
brain/worker.ts
web/voice/sentenceStreamer.ts


FAS 8 ‚Äî Vision & sensorer (minimalt)
M√•l: YOLO-driven n√§rvaro ‚Üí vision_event som p√•verkar ton.
YOLO pipeline (lokalt):


Input: kamera-frame ‚Üí etiketter/ansikten (om p√•slaget).


Output: Artifact{kind:"vision_event", text:"ler", score:0.8, meta:{camera:"desk"}}


Regel i Alice Core: om vision_event: ler ‚Üí justera mood = ‚Äúglad‚Äù.


Done n√§r: en enkel demo reagerar p√• leende (varmare h√§lsning).


Filer
vision/yolo.ts
server/api/vision/ingest.ts  # om du skickar upp frames via lokalt endpoint


FAS 9 ‚Äî EmotionEngine (prosodi ‚Üí stil/SSML)
M√•l: Levande k√§nsla via tempo/pitch/ton och kort svensk stil.
Engine

 export type Mood = "neutral"|"glad"|"fokuserad"|"frustrerad";
export interface EmotionState { mood:Mood; speakingRate:number; pitch:number; updatedAt:number }
export interface EmotionEngine {
  updateFromAudio(frame:Int16Array, sr:number): EmotionState;
  get(): EmotionState;
}


SSML: mappa mood ‚Üí <prosody rate="0.95" pitch="-2%">.


Done n√§r: MOS-betyg f√∂rb√§ttras vs baseline; logg emotion_state_updated.


Filer
core/emotion/engine.ts
web/voice/ssml.ts


FAS 10 ‚Äî Fler verktyg (RAG + kamera + HA)
M√•l: Ut√∂ka verktyg utan att r√∂ra UI.
kb.search (POST /api/tools/kb.search)

 { query:string, top_k?:number } -> { hits:[{id,score,title}] }


kb.fetch (POST /api/tools/kb.fetch)

 { ids:string[] } -> { docs:[{id,title,text}]} 


camera.control (POST /api/tools/camera.control)

 { camera_id:string, action:"snapshot"|"ptz_preset"|"set_ir"|"set_motion"|"set_privacy", args?:any }


HA lyssnare (om p√•slaget): integrations/ha/ws_client.ts


Done n√§r: minst 1 lokalt verktyg (snapshot) och 1 RAG-verktyg anv√§nds av agenten.



FAS 11 ‚Äî Test & QA (nya tester)
M√•l: Bekr√§fta Strict TTS, injektion, brain-latens.
Selftests


scripts/selftest/01_strict_tts.ts ‚Äî verifiera att TTS == spoken_text.


scripts/selftest/02_injection_budget.ts ‚Äî tokens ‚â§ 25%.


scripts/selftest/03_brain_first_sentence.ts ‚Äî p50 ‚â§ 600 ms.


scripts/selftest/04_fallback.ts ‚Äî forcera delay ‚Üí fallback rate < 5%.


Done n√§r: alla tester PASS lokalt och i CI.



FAS 12 ‚Äî Observability & SLO
M√•l: M√§ta det som g√∂r Alice ‚Äúlevande‚Äù.
Metriker (server)


brain_first_sentence_ms, tts_ttfa_ms, e2e_ms


artifact_injection_rate, injected_tokens_pct, memory_hit_rate


fallback_rate, tool_error_rate


mood_switch_latency_ms


Dashboard: p50/p95/p99, senaste 50 turer.


SLO: Tillg√§nglighet 99.5%, e2e p95 ‚â§ 2.5 s, fallback < 5%.


Done n√§r: dashboard visar data live; larm konfigurerade.



FAS 13 ‚Äî Release-ops & CI/CD
M√•l: En-knapps deploy med rollback.
Docker (backend, web, nginx, supervisord) ‚Äì redan p√•b√∂rjat ‚Üí slutf√∂r.


GitHub Actions (CI/CD)


build ‚Üí test ‚Üí docker build/push ‚Üí deploy (staging/prod)


warnings as errors (tsc --noEmit, ESLint, build)


Secrets via CI/host (inga NEXT_PUBLIC_* hemligheter)


Done n√§r: main merge ‚Üí staging auto; tag ‚Üí prod; rollback-script funkar.



FAS 14 ‚Äî Canary & Runbook
M√•l: Trygg produktion.
Canary: allow-list (5 anv√§ndare), flagga FEATURE_ROLLOUT=pilot_5.


Runbook (1-pager): ‚ÄúOm X ‚Üí g√∂r Y‚Äù (WS-drop, 429, agent 5xx, brain timeout).


Done n√§r: canary k√∂rs 1‚Äì2 dagar utan regress; kontrollerad rollback testad.



FAS 15 ‚Äî (Valfritt) Avancerat minne & kedjor
M√•l: Mer autonom ‚Äúentitet‚Äù.
Mem0-driver (semantiskt minne) ist√§llet f√∂r/ut√∂ver sqlite-vec.


On-chain ankare (privat): spara hash av high-confidence artefakter.


Wake-word (om du vill): Porcupine/Silero via WASM, ovanp√• VAD.


Done n√§r: minnen k√§nns mer proaktiva och stabila √∂ver l√•nga perioder.



Snabb Go/No-Go f√∂r release
Strict TTS aktiv, 0 avvikelser mellan TTS och spoken_text.


brain_first_sentence_ms p50 ‚â§ 600, tts_ttfa_ms p50 ‚â§ 300, e2e p95 ‚â§ 1.2s.


artifact_injection_rate 30‚Äì70%, injected_tokens_pct ‚â§ 25%.


Fallback < 5%.


0√ó5xx i 100 sekventiella /api/agent.


CI/CD gr√∂nt, rollback testad, canary OK.



Vad du kan g√∂ra direkt (b√∂rja med FAS 1‚Äì3)
Skapa /api/brain/compose med AnswerPackage.


Koppla Strict TTS i voice-binding (l√•t TTS l√§sa exakt paketet).


L√§gg artifacts-tabell + Memory.write/fetch.


Aktivera EventBus och b√∂rja logga.


Yes! H√§r f√•r du f√§rdiga TypeScript-stubs f√∂r FAS 1‚Äì3 som du kan l√§gga in rakt av utan att r√∂ra UI:t.
 De inneh√•ller:
FAS 1: /api/brain/compose + AnswerPackage + Strict-TTS-hj√§lpare


FAS 2: EventBus + NDJSON-telemetri


FAS 3: Memory API (in-memory driver som standard) + endpoints /memory/write & /memory/fetch


Dessutom: plats f√∂r n√§tverkskameror/HA i eventtyperna (hooks redo), och en enkel voice-integration helper f√∂r att koppla din befintliga r√∂stpipeline till /api/brain/compose.
Antaganden: Next.js App Router med app/api/.../route.ts, Node-runtime.
 Om du k√∂r Pages Router: flytta route.ts till pages/api/*.ts och exportera default-handler.

üìÅ Filstruktur (l√§gg till)
src/
  brain/compose.ts
  core/eventBus.ts
  core/metrics.ts
  memory/index.ts
  memory/inMemory.ts
  memory/sqlite.ts          # valfri ‚Äì stub om du vill byta driver
  memory/types.ts
  types/answer.ts
  types/events.ts
web/
  voice/strictTts.ts
  voice/sentenceStreamer.ts  # stub ‚Äì aktivera n√§r du vill streama meningar
  voice/useStrictTTS.ts      # helper att koppla in i befintlig pipeline
app/
  api/brain/compose/route.ts
  api/memory/fetch/route.ts
  api/memory/write/route.ts


FAS 1 ‚Äî Brain Compose (Strict TTS)
src/types/answer.ts
export interface AnswerPackage {
  spoken_text: string;              // exakt vad TTS ska l√§sa upp
  screen_text?: string;             // kort text till UI
  ssml?: string;                    // om satt ‚Äì anv√§nd denna f√∂re spoken_text
  citations?: { title: string; url?: string }[];
  meta?: { confidence: number; tone?: string };
}

src/brain/compose.ts (stub ‚Äì koppla GPT-OSS h√§r inne)
import { AnswerPackage } from "../types/answer";
import { emit } from "../core/eventBus";

export interface BrainComposeInput {
  user_id: string;
  session_id: string;
  text: string;
  locale: "sv-SE" | string;
}

export async function composeAnswer(input: BrainComposeInput): Promise<AnswerPackage> {
  const t0 = Date.now();

  // TODO: ers√§tt med din GPT-OSS + RAG + tools och bygg paketet nedan.
  const pkg: AnswerPackage = {
    spoken_text: `Jag h√∂rde: "${input.text}". (Stubbsvar ‚Äì koppla GPT-OSS h√§r.)`,
    screen_text: `Stubb: ${input.text}`,
    meta: { confidence: 0.75, tone: "v√§nlig" }
  };

  emit("brain_compose", {
    t_ms: Date.now() - t0,
    user_id: input.user_id,
    session_id: input.session_id,
    text_len: input.text?.length || 0
  });

  return pkg;
}

app/api/brain/compose/route.ts
import { NextRequest, NextResponse } from "next/server";
import { composeAnswer } from "@/src/brain/compose";
import { emit } from "@/src/core/eventBus";

export const runtime = "nodejs";

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const { user_id, session_id, text, locale = "sv-SE" } = body || {};
    if (!user_id || !session_id || !text) {
      return NextResponse.json({ error: "Missing user_id, session_id or text" }, { status: 400 });
    }

    const pkg = await composeAnswer({ user_id, session_id, text, locale });
    emit("agent_response", { user_id, session_id, kind: "brain_pkg", len: pkg.spoken_text.length });

    return NextResponse.json(pkg, { status: 200 });
  } catch (err: any) {
    return NextResponse.json({ error: err?.message || "compose failed" }, { status: 500 });
  }
}

web/voice/strictTts.ts (hj√§lpare f√∂r Strict-TTS)
import type { AnswerPackage } from "@/src/types/answer";

export interface TTSLike {
  speak(input: { text?: string; ssml?: string }): Promise<void>;
}

export async function speakAnswerPackage(tts: TTSLike, pkg: AnswerPackage) {
  const ssml = pkg.ssml?.trim();
  if (ssml && ssml.startsWith("<speak")) {
    await tts.speak({ ssml });
  } else {
    await tts.speak({ text: pkg.spoken_text });
  }
}

web/voice/useStrictTTS.ts (koppla till din befintliga voice-pipeline)
import { speakAnswerPackage } from "./strictTts";

export async function handleAsrFinal({
  userId, sessionId, text, tts
}: { userId: string; sessionId: string; text: string; tts: { speak:(p:{text?:string; ssml?:string})=>Promise<void> } }) {
  // Anropa hj√§rnan (OSS) f√∂r att komponera svaret ‚Üí Strict TTS
  const resp = await fetch("/api/brain/compose", {
    method: "POST",
    headers: { "content-type": "application/json" },
    body: JSON.stringify({ user_id: userId, session_id: sessionId, text, locale: "sv-SE" })
  });

  if (!resp.ok) throw new Error(`brain/compose failed: ${resp.status}`);
  const pkg = await resp.json();
  await speakAnswerPackage(tts, pkg);
  return pkg;
}

web/voice/sentenceStreamer.ts (valfri ‚Äì aktivera n√§r du vill streama)
export function streamToSentences(textStream: AsyncIterable<string>, onSentence:(s:string)=>void) {
  let buf = "";
  (async () => {
    for await (const chunk of textStream) {
      buf += chunk;
      const parts = buf.split(/([.!?]+)\s+/);
      for (let i=0; i<parts.length-1; i+=2) {
        const sentence = (parts[i] + (parts[i+1]||"")).trim();
        if (sentence) onSentence(sentence);
      }
      buf = parts[parts.length-1] || "";
    }
    if (buf.trim()) onSentence(buf.trim());
  })().catch(console.error);
}


FAS 2 ‚Äî EventBus & NDJSON-telemetri
src/types/events.ts
export type EventType =
  | "asr_final" | "agent_response" | "tool_call" | "tool_result"
  | "brain_compose" | "tts_start" | "tts_end"
  | "vision_event" | "ha_state_changed";

export interface EventEnvelope<T=any> {
  type: EventType;
  ts: number;
  payload: T;
}

src/core/eventBus.ts
import { EventEmitter } from "events";
import { logNDJSON } from "./metrics";
import type { EventEnvelope, EventType } from "../types/events";

export const bus = new EventEmitter();

export function emit<T=any>(type: EventType, payload: T) {
  const ev: EventEnvelope<T> = { type, ts: Date.now(), payload };
  bus.emit(type, ev);
  logNDJSON(ev);
}

export function on<T=any>(type: EventType, h: (ev: EventEnvelope<T>) => void) {
  bus.on(type, h);
}

src/core/metrics.ts
import fs from "fs";
import path from "path";

const dir = path.join(process.cwd(), "logs");
if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
const file = path.join(dir, "metrics.ndjson");

export function logNDJSON(obj: any) {
  try {
    const line = JSON.stringify(obj);
    fs.appendFileSync(file, line + "\n", "utf8");
  } catch (e) {
    // swallow
  }
}

H√§r kan vi senare l√§gga till aggregator (p50/p95 osv). F√∂r nu loggar vi h√§ndelserna.

FAS 3 ‚Äî Memory & RAG (artefakter)
src/memory/types.ts
export type ArtifactKind = "insight"|"kb_chunk"|"plan"|"policy"|"vision_event";

export interface Artifact {
  id: string;
  userId: string;
  kind: ArtifactKind;
  text: string;
  score: number;                 // 0..1
  expiresAt?: string;            // ISO
  meta?: Record<string, any>;
  embedding?: number[];          // valfritt f√§lt (f√∂r sqlite-vec senare)
}

export interface Memory {
  write(a: Artifact): Promise<void>;
  fetch(userId: string, k: number, kinds?: ArtifactKind[]): Promise<Artifact[]>;
}

src/memory/inMemory.ts (defaultdriver ‚Äì noll beroenden)
import type { Artifact, Memory, ArtifactKind } from "./types";
import { randomUUID } from "crypto";

const store = new Map<string, Artifact[]>(); // key=userId

export const InMemoryMemory: Memory = {
  async write(a: Artifact) {
    const id = a.id || randomUUID();
    const arr = store.get(a.userId) || [];
    arr.unshift({ ...a, id });
    store.set(a.userId, arr.slice(0, 500)); // enkel cap
  },
  async fetch(userId: string, k: number, kinds?: ArtifactKind[]) {
    let arr = store.get(userId) || [];
    if (kinds?.length) arr = arr.filter(a => kinds.includes(a.kind));
    return arr
      .filter(a => !a.expiresAt || new Date(a.expiresAt) > new Date())
      .sort((a,b)=> (b.score - a.score))
      .slice(0, k);
  }
};

src/memory/sqlite.ts (valfri ‚Äì stub klar att fylla p√•)
// Optional: byt till denna n√§r du vill k√∂ra sqlite-vec.
import type { Memory, Artifact, ArtifactKind } from "./types";

export function createSqliteMemory(dbPath = "data/alice.db"): Memory {
  // TODO: implementera med better-sqlite3/sqlite-vec
  // create table if not exists artifacts (id TEXT PK, user_id TEXT, kind TEXT, text TEXT, score REAL, expires_at TEXT, meta_json TEXT, embedding BLOB)
  return {
    async write(a: Artifact) { throw new Error("SQLite driver not implemented yet"); },
    async fetch(userId: string, k: number, kinds?: ArtifactKind[]) { return []; }
  };
}

src/memory/index.ts
import type { Memory } from "./types";
import { InMemoryMemory } from "./inMemory";
// import { createSqliteMemory } from "./sqlite";

let memory: Memory = InMemoryMemory;
// if (process.env.MEMORY_DRIVER === "sqlite") memory = createSqliteMemory(process.env.SQLITE_PATH);

export default memory;

app/api/memory/write/route.ts
import { NextRequest, NextResponse } from "next/server";
import memory from "@/src/memory";
import type { Artifact } from "@/src/memory/types";
export const runtime = "nodejs";

export async function POST(req: NextRequest) {
  try {
    const art = (await req.json()) as Artifact;
    if (!art?.userId || !art?.kind || !art?.text) {
      return NextResponse.json({ error: "userId, kind, text required" }, { status: 400 });
    }
    await memory.write(art);
    return NextResponse.json({ ok: true }, { status: 200 });
  } catch (e:any) {
    return NextResponse.json({ error: e?.message || "write failed" }, { status: 500 });
  }
}

app/api/memory/fetch/route.ts
import { NextRequest, NextResponse } from "next/server";
import memory from "@/src/memory";
import type { ArtifactKind } from "@/src/memory/types";
export const runtime = "nodejs";

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const { user_id, k = 5, kinds } = body || {};
    if (!user_id) return NextResponse.json({ error: "user_id required" }, { status: 400 });
    const arts = await memory.fetch(user_id, Number(k), kinds as ArtifactKind[] | undefined);
    return NextResponse.json({ artifacts: arts }, { status: 200 });
  } catch (e:any) {
    return NextResponse.json({ error: e?.message || "fetch failed" }, { status: 500 });
  }
}


‚úÖ Voice-pipeline: ‚Äúhar vi klart, bara integrera?‚Äù
Ja. Din r√∂stpipeline √§r redan klar ‚Äî det enda du g√∂r √§r att anropa handleAsrFinal() (fr√•n web/voice/useStrictTTS.ts) n√§r du f√•r en stabil ASR-partial eller final. Den funktionen kallar /api/brain/compose, och spelar sedan upp exakt det som paketet s√§ger (Strict-TTS).
Pseudointegration i din befintliga voiceBinding:
import { handleAsrFinal } from "@/web/voice/useStrictTTS";

onAsrStableFinal(async (text) => {
  try {
    const pkg = await handleAsrFinal({
      userId: session.userId,
      sessionId: session.id,
      text,
      tts: TTSAdapterInstance
    });
    ui.show(pkg.screen_text, pkg.citations);
  } catch (e) {
    console.error(e);
    // valfri fallback: visa textl√§ge
  }
});


üì∑ N√§tverkskameror & Home Assistant (HA)
Ing√•r inte i FAS 1‚Äì3 (medvetet, f√∂r att du ska kunna g√• live direkt).


Men: src/types/events.ts och EventBus/Memory √§r redan f√∂rberedda f√∂r att ta emot:


vision_event (YOLO/SAM/ansiktsmatch)


ha_state_changed (Home Assistant)


N√§r du √§r redo i n√§sta fas l√§gger vi till:


integrations/ha/ws_client.ts (HA-WebSocket)


vision/yolo.ts och ett /api/vision/ingest om du vill pusha frames lokalt


tools/camera.control (MCP-verktyg) ‚Üí agenten kan ta snapshots/styra PTZ



üß™ Snabb sanity-check (efter att du lagt in filerna)
npm run build ‚Üí ska kompilera utan nya varningar.


POST /api/brain/compose med body:


{ "user_id":"u1", "session_id":"s1", "text":"Hej Alice!", "locale":"sv-SE" }

‚Üí 200 + stub-paket.
 3) K√∂r /voice-test, s√§g n√•got ‚Üí TTS l√§ser stubbsvar (Strict-TTS).
 4) POST /api/memory/write med ett enkelt insight ‚Üí POST /api/memory/fetch ‚Üí artefakt tillbaka.
 5) Kika i logs/metrics.ndjson ‚Üí eventrader skrivs.



Kort svar: n√§stan allt √§r med ‚Äì planen och stubs t√§cker FAS 1‚Äì3 snyggt.
 Det som √•terst√•r √§r mest sm√• ‚Äúlimbitar‚Äù s√• allt flyter i drift:
Saknas / att l√§gga till (kompakt gap-lista)
PromptBuilder (FAS 4) ‚Äì stub
 ‚Äì Selektiv injektion (‚â§ 25%) + komprimering av artefakter + persona/style.


Embeddings-pipeline
 ‚Äì Funktion som ber√§knar embedding + bakgrundsjobb som fyller embedding f√∂r nya artefakter.
 ‚Äì (SQLite-driver kan v√§nta, men beh√∂ver du RAG p√• riktigt vill du ha detta.)


Provider-switch & cancel
 ‚Äì Abort/Cancel p√• p√•g√•ende /api/brain/compose vid barge-in, och fallback-policy (deadline ‚Üí /api/agent).


Streaming f√∂rsta meningen (senare FAS 7)
 ‚Äì En SSE/WS-variant av /api/brain/compose som skickar first_sentence tidigt.


SSML-s√§kerhet
 ‚Äì Escape/validering s√• att felaktig text inte bryter SSML.


Aggregerad telemetri
 ‚Äì Enkel p50/p95-aggregator √∂ver metrics.ndjson + /api/metrics/summary.


Inputvalidering
 ‚Äì Zod/validering f√∂r alla JSON-payloads (compose/memory).


St√§d/TTL
 ‚Äì Cron/worker som rensar utg√•ngna artefakter och loggar.


Persona/Style-inneh√•ll
 ‚Äì Fyll faktiskt inneh√•ll i alice/identity/persona.yml & style.yml (vi har bara platsen).


HA/Camera wiring (n√§sta fas)
 ‚Äì Stubs finns i eventtyper; l√§gg integrations/ha/ws_client.ts + vision/yolo.ts n√§r du aktiverar.


Mini-patch kit (sm√• stubs du kan l√§gga in direkt)
1) core/promptBuilder.ts (FAS 4 ‚Äì injektionsbudget)
import type { Artifact } from "@/src/memory/types";

export function compressArtifacts(arts: Artifact[], maxChars = 1500) {
  // trivial komprimering: join + trunca ‚Äì byt mot riktig summarizer senare
  const s = arts.map(a => `‚Ä¢ [${a.kind}] ${a.text}`).join("\n");
  return s.length > maxChars ? s.slice(0, maxChars - 1) + "‚Ä¶" : s;
}

export function buildSystemPrompt(persona: string, style: string, context: string) {
  return [
    { role: "system", content: persona.trim() },
    { role: "system", content: `Stil:\n${style.trim()}` },
    { role: "system", content: `Kontext:\n${context.trim()}` },
  ];
}

2) src/embeddings/compute.ts
export async function embed(text: string): Promise<number[]> {
  // TODO: byt till riktig modell (t.ex. bge-small eller lokal WebGPU)
  // tempor√§r dummy ‚Äì g√∂r inte RAG ‚Äúp√• riktigt‚Äù men h√•ller API:t stabilt
  const v = new Array(384).fill(0).map((_,i)=>((i*9973 + text.length*31)%101)/100);
  return v;
}

3) Hooka embeddings i Memory-write (FAS 3)
I app/api/memory/write/route.ts ‚Äì ber√§kna embedding om saknas:
import { embed } from "@/src/embeddings/compute";
// ...
const art = (await req.json()) as Artifact;
if (!art.embedding) art.embedding = await embed(art.text);

4) Abort/fallback f√∂r compose (FAS 5)
Uppdatera web/voice/useStrictTTS.ts:
export async function handleAsrFinal({ userId, sessionId, text, tts }: {...}) {
  const ctrl = new AbortController();
  // spara ctrl i din session s√• barge-in kan kalla ctrl.abort()
  const timer = setTimeout(()=>ctrl.abort("brain deadline"), 1500);

  const resp = await fetch("/api/brain/compose", {
    method: "POST",
    headers: { "content-type": "application/json" },
    body: JSON.stringify({ user_id:userId, session_id:sessionId, text, locale:"sv-SE" }),
    signal: ctrl.signal
  }).catch(e => ({ ok:false, statusText:String(e) } as any));

  clearTimeout(timer);
  if (!resp?.ok) {
    // fallback: l√•t /api/agent (cloud lane) hantera denna tur
    const fb = await fetch("/api/agent", { method:"POST", body: JSON.stringify({ text }) });
    const pkg = await fb.json(); // mappa till AnswerPackage i din provider
    await speakAnswerPackage(tts, pkg);
    return pkg;
  }
  const pkg = await resp.json();
  await speakAnswerPackage(tts, pkg);
  return pkg;
}

Tips: L√§gg √§ven cancel() i TTS-interfacet (din voice-adapter har redan barge-in):
 export interface TTSLike { speak(...):Promise<void>; cancel?():void }
5) /api/metrics/summary (p50/p95 ‚Äì snabb)
// app/api/metrics/summary/route.ts
import { NextResponse } from "next/server";
import fs from "fs"; import path from "path";
export const runtime = "nodejs";
function pct(arr:number[], p:number){ if(!arr.length) return 0; const i=Math.floor((p/100)*arr.length); return arr.sort((a,b)=>a-b)[Math.min(i,arr.length-1)] }
export async function GET() {
  const file = path.join(process.cwd(), "logs", "metrics.ndjson");
  if (!fs.existsSync(file)) return NextResponse.json({ ok:true, metrics:{} });
  const lines = fs.readFileSync(file,"utf8").trim().split("\n").slice(-5000);
  const e2e:number[] = [];
  for (const l of lines) {
    try { const ev = JSON.parse(l); if (ev.type==="agent_response" && ev.payload?.e2e_ms) e2e.push(ev.payload.e2e_ms); } catch {}
  }
  return NextResponse.json({ ok:true, e2e:{ p50:pct(e2e,50), p95:pct(e2e,95), n:e2e.length }});
}

6) SSML-escape (enkelt skydd)
export function toSSMLSafe(text:string){
  return `<speak xml:lang="sv-SE">${text
    .replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;")}</speak>`;
}


Svar p√• dina tv√• sista fr√•gor
N√§tverkskameror & HA: plats och events √§r f√∂rberedda ( vision_event, ha_state_changed ), men sj√§lva klienterna/verktygen l√§gger vi in i n√§sta fas (FAS 8/FAS 10).


Voice-pipen: ja, den √§r klar ‚Äì du beh√∂ver bara koppla handleAsrFinal() in i ditt voiceBinding (som i exemplet). Barge-in och device-fallbacks finns redan i din pipeline; l√§gg g√§rna till tts.cancel?.() vid avbrott.


Grymt ‚Äî h√§r kommer en f√§rdig SQLite-driver med ensureSchema(), klar att toggla via env och kompatibel med dina befintliga stubs. Den funkar direkt utan sqlite-vec, men f√∂rberedd f√∂r att ladda sqlite-vec om du pekar ut en .so/.dylib/.dll. Inkluderar WAL, index, upsert, och enkel vektors√∂k-fallback i JS.

1) Installera beroenden
npm i better-sqlite3
# (valfritt) du kan senare h√§mta sqlite-vec och s√§tta SQLITE_VEC_PATH=/path/to/sqlite-vec.dylib

Milj√∂:
MEMORY_DRIVER=sqlite
SQLITE_PATH=./data/alice.db
SQLITE_VEC_PATH=            # valfritt: absolut/relativ s√∂kv√§g till sqlite-vec


2) Drop-in driver (ers√§tt din stub)
src/memory/sqlite.ts
import Database from "better-sqlite3";
import { randomUUID } from "crypto";
import fs from "fs";
import path from "path";
import type { Memory, Artifact, ArtifactKind } from "./types";

type SqliteRow = {
  id: string; user_id: string; kind: string; text: string; score: number;
  expires_at: string | null; meta_json: string | null; embedding: Buffer | null; created_at: string;
};

function toBuf(vec?: number[]): Buffer | null {
  if (!vec || !vec.length) return null;
  const f32 = new Float32Array(vec);
  return Buffer.from(f32.buffer);
}

function fromBuf(buf: Buffer | null): number[] | undefined {
  if (!buf) return undefined;
  const f32 = new Float32Array(buf.buffer, buf.byteOffset, Math.floor(buf.byteLength / 4));
  return Array.from(f32);
}

function cosine(a: number[], b: number[]): number {
  let dot = 0, na = 0, nb = 0;
  for (let i = 0; i < a.length && i < b.length; i++) {
    dot += a[i] * b[i]; na += a[i] * a[i]; nb += b[i] * b[i];
  }
  const denom = Math.sqrt(na) * Math.sqrt(nb) || 1e-9;
  return dot / denom;
}

function ensureDir(p: string) {
  const d = path.dirname(p); if (!fs.existsSync(d)) fs.mkdirSync(d, { recursive: true });
}

function loadSqliteVec(db: Database.Database, extPath?: string) {
  try {
    if (extPath && fs.existsSync(extPath)) {
      db.loadExtension(extPath);
      return true;
    }
  } catch (e) {
    // Extension load failed ‚Üí continue without vec
  }
  return false;
}

function ensureSchema(db: Database.Database, vecLoaded: boolean) {
  db.pragma("journal_mode = WAL");
  db.exec(`
    CREATE TABLE IF NOT EXISTS artifacts (
      id TEXT PRIMARY KEY,
      user_id TEXT NOT NULL,
      kind TEXT NOT NULL,
      text TEXT NOT NULL,
      score REAL NOT NULL DEFAULT 0.0,
      expires_at TEXT,
      meta_json TEXT,
      embedding BLOB,
      created_at TEXT NOT NULL DEFAULT (datetime('now'))
    );
    CREATE INDEX IF NOT EXISTS idx_artifacts_user_kind_score ON artifacts(user_id, kind, score DESC, created_at DESC);
    CREATE INDEX IF NOT EXISTS idx_artifacts_expiry ON artifacts(expires_at);
  `);

  // (Valfritt) sqlite-vec ‚Äì skapa en separat tabell f√∂r ANN om du vill,
  // men vi klarar oss utan f√∂r nu (vi anv√§nder JS fallback).
  if (vecLoaded) {
    // Exempel om du vill spegla embeddings i en vektor-tabell:
    // db.exec(`CREATE VIRTUAL TABLE IF NOT EXISTS vec_artifacts USING vec0(embedding float[384]);`);
    // Du kan sen h√•lla en trigger i sync. Vi hoppar det tills du vill k√∂ra riktig ANN.
  }
}

export function createSqliteMemory(dbPath = process.env.SQLITE_PATH || "data/alice.db"): Memory & {
  searchSimilar?: (userId: string, queryEmb: number[], k: number, kinds?: ArtifactKind[]) => Promise<Artifact[]>;
} {
  ensureDir(dbPath);
  const db = new Database(dbPath);

  const vecLoaded = loadSqliteVec(db, process.env.SQLITE_VEC_PATH);
  ensureSchema(db, vecLoaded);

  // Statements
  const upsert = db.prepare(`
    INSERT INTO artifacts (id, user_id, kind, text, score, expires_at, meta_json, embedding)
    VALUES (@id, @user_id, @kind, @text, @score, @expires_at, @meta_json, @embedding)
    ON CONFLICT(id) DO UPDATE SET
      user_id=excluded.user_id, kind=excluded.kind, text=excluded.text,
      score=excluded.score, expires_at=excluded.expires_at,
      meta_json=excluded.meta_json, embedding=excluded.embedding
  `);

  const selectTop = db.prepare(`
    SELECT * FROM artifacts
     WHERE user_id = ? AND (? = 0 OR kind IN (%kinds))
       AND (expires_at IS NULL OR expires_at > datetime('now'))
     ORDER BY score DESC, created_at DESC
     LIMIT ?
  `);

  function bindKinds(sql: string, kinds?: ArtifactKind[]) {
    if (!kinds || kinds.length === 0) {
      return { sql: sql.replace("(? = 0 OR kind IN (%kinds))", "1 = 1"), params: [] as any[] };
    }
    const placeholders = kinds.map(() => "?").join(",");
    const s = sql.replace("%kinds", placeholders).replace("(? = 0 OR kind IN (%kinds))", `kind IN (${placeholders})`);
    return { sql: s, params: kinds };
  }

  const api: Memory & {
    searchSimilar?: (userId: string, queryEmb: number[], k: number, kinds?: ArtifactKind[]) => Promise<Artifact[]>;
  } = {
    async write(a: Artifact) {
      const id = a.id || randomUUID();
      upsert.run({
        id,
        user_id: a.userId,
        kind: a.kind,
        text: a.text,
        score: a.score ?? 0,
        expires_at: a.expiresAt ?? null,
        meta_json: a.meta ? JSON.stringify(a.meta) : null,
        embedding: toBuf(a.embedding)
      });
    },

    async fetch(userId: string, k: number, kinds?: ArtifactKind[]) {
      const { sql, params } = bindKinds(selectTop.source, kinds);
      const rows = db.prepare(sql).all(userId, kinds?.length ? 1 : 0, ...params, k) as SqliteRow[];
      return rows.map(r => ({
        id: r.id,
        userId: r.user_id,
        kind: r.kind as ArtifactKind,
        text: r.text,
        score: r.score,
        expiresAt: r.expires_at || undefined,
        meta: r.meta_json ? JSON.parse(r.meta_json) : undefined,
        embedding: fromBuf(r.embedding)
      }));
    },

    // Valfri vektors√∂k: JS-fallback (h√§mtar topp 500 och sorterar p√• cosine).
    async searchSimilar(userId: string, queryEmb: number[], k: number, kinds?: ArtifactKind[]) {
      // H√§mta kandidater (score-sorterat); justera 500 vid behov.
      const candidates = await this.fetch(userId, 500, kinds);
      const scored = candidates
        .filter(c => Array.isArray(c.embedding) && c.embedding.length)
        .map(c => ({ c, sim: cosine(queryEmb, c.embedding as number[]) }))
        .sort((a, b) => b.sim - a.sim)
        .slice(0, k)
        .map(x => x.c);
      return scored.length ? scored : candidates.slice(0, k);
    }
  };

  return api;
}


src/memory/index.ts (byt driver via env)
import type { Memory } from "./types";
import { InMemoryMemory } from "./inMemory";
import { createSqliteMemory } from "./sqlite";

let memory: Memory;

switch (process.env.MEMORY_DRIVER) {
  case "sqlite":
    memory = createSqliteMemory(process.env.SQLITE_PATH);
    break;
  default:
    memory = InMemoryMemory;
}

export default memory;


3) (Valfritt) Automatisk embedding i write-endpoint
Vill du ber√§kna embedding i API:t om saknas (s√• klienter slipper g√∂ra det), l√§gg till i din app/api/memory/write/route.ts:
import { embed } from "@/src/embeddings/compute"; // din stub

// ...
const art = (await req.json()) as Artifact;
if (!art?.userId || !art?.kind || !art?.text) {
  return NextResponse.json({ error: "userId, kind, text required" }, { status: 400 });
}
if (!art.embedding) {
  try { art.embedding = await embed(art.text); } catch {}
}
await memory.write(art);

Du har redan en enkel embed()-stub; byt till riktig modell n√§r du vill.

4) Snabb sanity-k√∂rning
# 1) s√§tt env
export MEMORY_DRIVER=sqlite
export SQLITE_PATH=./data/alice.db

# 2) k√∂r upp dev / build
npm run dev   # eller npm run build && npm run start

# 3) skriv ett minne
curl -X POST localhost:3000/api/memory/write \
  -H 'content-type: application/json' \
  -d '{"userId":"u1","kind":"insight","text":"Anv√§ndaren bor i G√∂teborg","score":0.82}'

# 4) h√§mta minnen
curl -X POST localhost:3000/api/memory/fetch \
  -H 'content-type: application/json' \
  -d '{"user_id":"u1","k":5}'


5) Tips f√∂r produktion
WAL √§r p√•; l√§gg PRAGMA synchronous = NORMAL om du vill √∂ka throughput.


K√∂r SQLite-filen p√• SSD och l√§gg data/ utanf√∂r repo.


Om/ n√§r du vill riktig ANN: skaffa sqlite-vec bin√§r och s√§tt SQLITE_VEC_PATH. D√• kan vi l√§gga till en speglande vec-tabell + triggers f√∂r ~millisekunders top-K-s√∂k.



Perfekt ‚Äî h√§r kommer f√§rdiga stubs f√∂r KB/RAG i samma stil som tidigare (drop-in, Next.js App Router). Du f√•r:
Datastore (SQLite): kb_docs + kb_chunks med embeddings och s√∂k


Endpoints (verktyg): /api/tools/kb.search och /api/tools/kb.fetch


Ingest: /api/kb/ingest (ren text eller fil-URL), enkel chunkning + embeddings


Tool-schemas (MCP/JSON Schema) f√∂r agentens toolcalling


Agent-koppling: minimal registry + eventlogg


Kr√§ver bara better-sqlite3 (som du redan installerat) och din embed()-stub fr√•n tidigare. Byt till riktig embeddingmodell n√§r du vill.

üìÅ Nya filer
src/
  kb/index.ts
  kb/sqlite.ts
  kb/types.ts
  kb/chunker.ts
app/
  api/kb/ingest/route.ts
  api/tools/kb.search/route.ts
  api/tools/kb.fetch/route.ts
tools/
  kb.search.schema.json
  kb.fetch.schema.json
server/
  agent/tools/registry.ts

Milj√∂ (l√§gg till i .env.local / prod):
MEMORY_DRIVER=sqlite
SQLITE_PATH=./data/alice.db


src/kb/types.ts
export interface KBDoc {
  id: string;
  title: string;
  source?: string;       // t.ex. filnamn/URL
  createdAt?: string;
  meta?: Record<string, any>;
}

export interface KBChunk {
  id: string;
  docId: string;
  text: string;
  ord: number;           // chunk-ordning i dokumentet
  embedding?: number[];  // Float32-embedding
}

src/kb/chunker.ts
// extremt enkel chunker ‚Äì byt mot t.ex. tokenbaserad senare
export function chunkText(text: string, maxLen = 800): string[] {
  const parts: string[] = [];
  let buf = "";
  for (const sent of text.split(/(?<=[.!?])\s+/)) {
    if ((buf + " " + sent).trim().length > maxLen) {
      if (buf.trim()) parts.push(buf.trim());
      buf = sent;
    } else {
      buf = (buf ? buf + " " : "") + sent;
    }
  }
  if (buf.trim()) parts.push(buf.trim());
  return parts;
}

src/kb/sqlite.ts
import Database from "better-sqlite3";
import fs from "fs"; import path from "path";
import { randomUUID } from "crypto";
import type { KBDoc, KBChunk } from "./types";
import { embed } from "@/src/embeddings/compute"; // din stub
import { logNDJSON } from "@/src/core/metrics";

function ensureDir(p: string) {
  const d = path.dirname(p); if (!fs.existsSync(d)) fs.mkdirSync(d, { recursive: true });
}
function toBuf(vec?: number[]): Buffer | null {
  if (!vec?.length) return null;
  const arr = new Float32Array(vec);
  return Buffer.from(arr.buffer);
}
function fromBuf(buf: Buffer | null): number[]|undefined {
  if (!buf) return undefined;
  const f = new Float32Array(buf.buffer, buf.byteOffset, Math.floor(buf.byteLength/4));
  return Array.from(f);
}
function cosine(a: number[], b: number[]): number {
  let dot=0,na=0,nb=0;
  for (let i=0;i<Math.min(a.length,b.length);i++){ dot+=a[i]*b[i]; na+=a[i]*a[i]; nb+=b[i]*b[i]; }
  const denom = Math.sqrt(na)*Math.sqrt(nb) || 1e-9;
  return dot/denom;
}

export class KBStore {
  private db: Database.Database;
  constructor(dbPath = process.env.SQLITE_PATH || "data/alice.db") {
    ensureDir(dbPath);
    this.db = new Database(dbPath);
    this.db.pragma("journal_mode = WAL");
    this.db.exec(`
      CREATE TABLE IF NOT EXISTS kb_docs(
        id TEXT PRIMARY KEY,
        title TEXT NOT NULL,
        source TEXT,
        meta_json TEXT,
        created_at TEXT NOT NULL DEFAULT (datetime('now'))
      );
      CREATE TABLE IF NOT EXISTS kb_chunks(
        id TEXT PRIMARY KEY,
        doc_id TEXT NOT NULL,
        ord INTEGER NOT NULL,
        text TEXT NOT NULL,
        embedding BLOB,
        FOREIGN KEY (doc_id) REFERENCES kb_docs(id) ON DELETE CASCADE
      );
      CREATE INDEX IF NOT EXISTS idx_kb_chunks_doc_ord ON kb_chunks(doc_id, ord);
    `);
  }

  async ingestText(title: string, text: string, source?: string, meta?: Record<string, any>) {
    const id = randomUUID();
    const insertDoc = this.db.prepare(`INSERT INTO kb_docs (id,title,source,meta_json) VALUES (?,?,?,?)`);
    insertDoc.run(id, title, source || null, meta ? JSON.stringify(meta) : null);

    // delay embeddings for throughput ‚Äì men vi k√∂r sync h√§r f√∂r enkelhet
    const { chunkText } = await import("./chunker");
    const chunks = chunkText(text);
    const insertChunk = this.db.prepare(`INSERT INTO kb_chunks (id,doc_id,ord,text,embedding) VALUES (?,?,?,?,?)`);
    let ord = 0;
    for (const c of chunks) {
      const emb = await embed(c);
      insertChunk.run(randomUUID(), id, ord++, c, toBuf(emb));
    }
    logNDJSON({ type:"kb_ingest", ts:Date.now(), payload:{ doc_id:id, chunks:chunks.length } });
    return id;
  }

  async fetchDocs(ids: string[]): Promise<KBDoc[]> {
    if (!ids?.length) return [];
    const q = `SELECT * FROM kb_docs WHERE id IN (${ids.map(()=>"?").join(",")})`;
    const rows = this.db.prepare(q).all(...ids) as any[];
    return rows.map(r => ({ id:r.id, title:r.title, source:r.source||undefined,
      createdAt:r.created_at, meta: r.meta_json ? JSON.parse(r.meta_json): undefined }));
  }

  async fetchChunks(ids: string[]): Promise<KBChunk[]> {
    if (!ids?.length) return [];
    const q = `SELECT * FROM kb_chunks WHERE id IN (${ids.map(()=>"?").join(",")})`;
    const rows = this.db.prepare(q).all(...ids) as any[];
    return rows.map(r => ({ id:r.id, docId:r.doc_id, text:r.text, ord:r.ord, embedding: fromBuf(r.embedding) }));
  }

  async search(query: string, k = 5): Promise<{chunk: KBChunk, score:number}[]> {
    // enkel JS-cosine √∂ver topp-N (h√§mta t.ex. senaste 5000 rader)
    const emb = await embed(query);
    const rows = this.db.prepare(`SELECT id,doc_id,ord,text,embedding FROM kb_chunks ORDER BY rowid DESC LIMIT 5000`).all() as any[];
    const scored = rows
      .filter(r => r.embedding)
      .map(r => {
        const v = fromBuf(r.embedding) || [];
        return { chunk: { id:r.id, docId:r.doc_id, text:r.text, ord:r.ord, embedding:v }, score: cosine(emb, v) };
      })
      .sort((a,b)=> b.score - a.score)
      .slice(0, k);
    return scored;
  }
}

let kbStore: KBStore | null = null;
export function getKB(): KBStore {
  if (!kbStore) kbStore = new KBStore();
  return kbStore;
}

src/kb/index.ts
export { getKB } from "./sqlite";
export * from "./types";


Endpoints (verktyg)
app/api/tools/kb.search/route.ts
import { NextRequest, NextResponse } from "next/server";
import { getKB } from "@/src/kb";
import { emit } from "@/src/core/eventBus";

export const runtime = "nodejs";

export async function POST(req: NextRequest) {
  try {
    const { query, top_k = 5 } = await req.json();
    if (!query) return NextResponse.json({ error: "query required" }, { status: 400 });
    const t0 = Date.now();
    const hits = await getKB().search(String(query), Number(top_k));
    const out = hits.map(h => ({
      chunk_id: h.chunk.id,
      doc_id: h.chunk.docId,
      ord: h.chunk.ord,
      preview: h.chunk.text.slice(0, 220),
      score: h.score
    }));
    emit("tool_result", { tool:"kb.search", ms: Date.now()-t0, n: out.length });
    return NextResponse.json({ hits: out }, { status: 200 });
  } catch (e:any) {
    return NextResponse.json({ error: e?.message || "kb.search failed" }, { status: 500 });
  }
}

app/api/tools/kb.fetch/route.ts
import { NextRequest, NextResponse } from "next/server";
import { getKB } from "@/src/kb";
import { emit } from "@/src/core/eventBus";

export const runtime = "nodejs";

export async function POST(req: NextRequest) {
  try {
    const { chunk_ids = [], doc_ids = [] } = await req.json();
    if (!chunk_ids.length && !doc_ids.length) {
      return NextResponse.json({ error: "chunk_ids or doc_ids required" }, { status: 400 });
    }
    const t0 = Date.now();
    const kb = getKB();
    const chunks = chunk_ids.length ? await kb.fetchChunks(chunk_ids) : [];
    const docs = doc_ids.length ? await kb.fetchDocs(doc_ids) : [];
    emit("tool_result", { tool:"kb.fetch", ms: Date.now()-t0, chunks: chunks.length, docs: docs.length });
    return NextResponse.json({
      docs,
      chunks: chunks.map(c => ({ id:c.id, doc_id:c.docId, ord:c.ord, text:c.text }))
    }, { status: 200 });
  } catch (e:any) {
    return NextResponse.json({ error: e?.message || "kb.fetch failed" }, { status: 500 });
  }
}


Ingestion
app/api/kb/ingest/route.ts
import { NextRequest, NextResponse } from "next/server";
import { getKB } from "@/src/kb";

export const runtime = "nodejs";

export async function POST(req: NextRequest) {
  try {
    const { title, text, source, meta, fetch_url } = await req.json();

    let bodyText = text;
    if (!bodyText && fetch_url) {
      const r = await fetch(fetch_url);
      if (!r.ok) return NextResponse.json({ error: `fetch failed ${r.status}` }, { status: 400 });
      bodyText = await r.text();
    }
    if (!title || !bodyText) {
      return NextResponse.json({ error: "title and (text|fetch_url) required" }, { status: 400 });
    }

    const id = await getKB().ingestText(String(title), String(bodyText), source, meta);
    return NextResponse.json({ ok:true, doc_id:id }, { status: 200 });
  } catch (e:any) {
    return NextResponse.json({ error: e?.message || "ingest failed" }, { status: 500 });
  }
}


Tool-schemas (f√∂r agent/MCP)
tools/kb.search.schema.json
{
  "name": "kb.search",
  "description": "Semantisk s√∂kning i lokal kunskapsbas. Returnerar topp-K chunkar med score.",
  "parameters": {
    "type": "object",
    "properties": {
      "query": { "type": "string", "description": "S√∂kfr√•ga i naturligt spr√•k" },
      "top_k": { "type": "integer", "minimum": 1, "maximum": 50, "default": 5 }
    },
    "required": ["query"]
  }
}

tools/kb.fetch.schema.json
{
  "name": "kb.fetch",
  "description": "H√§mta fulltext f√∂r chunkar eller metadata f√∂r dokument.",
  "parameters": {
    "type": "object",
    "properties": {
      "chunk_ids": { "type": "array", "items": { "type": "string" } },
      "doc_ids": { "type": "array", "items": { "type": "string" } }
    },
    "oneOf": [
      { "required": ["chunk_ids"] },
      { "required": ["doc_ids"] }
    ]
  }
}


Agent-koppling (exempel)
server/agent/tools/registry.ts
// Minimal registry f√∂r att mappa tool-namn ‚Üí HTTP-endpoint
export type ToolSpec = { name:string; schema:any; endpoint:string; method?:"POST"|"GET" };
export const toolRegistry: ToolSpec[] = [
  { name:"kb.search", schema: require("@/tools/kb.search.schema.json"), endpoint:"/api/tools/kb.search", method:"POST" },
  { name:"kb.fetch",  schema: require("@/tools/kb.fetch.schema.json"),  endpoint:"/api/tools/kb.fetch",  method:"POST" },
  // redan existerande:
  // { name:"timer.set", endpoint:"/api/tools/timer.set", method:"POST", schema: ... },
  // { name:"weather.get", endpoint:"/api/tools/weather.get", method:"POST", schema: ... },
];

I din agent-loop: n√§r LLM v√§ljer kb.search ‚Üí POSTa till endpoint, returnera hits till modellen; be den f√∂lja upp med kb.fetch p√• valda chunk_ids och anv√§nd texten i svaret (och/eller injicera i Strict-TTS-paketet).

Snabbtest (manuellt)
# 1) Ingesta text
curl -sX POST localhost:3000/api/kb/ingest \
 -H 'content-type: application/json' \
 -d '{"title":"DemoDoc","text":"Alice √§r din AI-assistent. Hon hj√§lper dig med v√§der och timers. Hon bor i webbl√§saren och pratar svenska."}'

# 2) S√∂k
curl -sX POST localhost:3000/api/tools/kb.search \
 -H 'content-type: application/json' \
 -d '{"query":"Vad g√∂r Alice?"}'

# 3) Fetch chunk
curl -sX POST localhost:3000/api/tools/kb.fetch \
 -H 'content-type: application/json' \
 -d '{"chunk_ids":["<ID_FR√ÖN_SEARCH>"]}'


Integration i Strict-TTS (RAG i hj√§rnan)
I din src/brain/compose.ts (d√§r GPT-OSS ska in) kan du g√∂ra:
// 1) H√§mta top-K chunkar:
const hits = await fetch("http://localhost:3000/api/tools/kb.search", {
  method:"POST", headers:{ "content-type":"application/json" },
  body: JSON.stringify({ query: input.text, top_k: 4 })
}).then(r=>r.json());

// 2) H√§mta fulltext f√∂r 2‚Äì3 chunkar:
const ids = hits?.hits?.slice(0,3).map((h:any)=>h.chunk_id) || [];
const chunks = ids.length ? await fetch("http://localhost:3000/api/tools/kb.fetch", {
  method:"POST", headers:{ "content-type":"application/json" },
  body: JSON.stringify({ chunk_ids: ids })
}).then(r=>r.json()) : { chunks: [] };

// 3) Skapa svarspaket (Strict TTS):
const context = (chunks.chunks||[]).map((c:any)=>c.text).join("\n---\n");
// ‚Ä¶mata in `context` i din lokala GPT-OSS prompt ‚Üí bygg AnswerPackage


Vad du har nu
Riktig RAG-s√∂kning lokalt (JS-cosine nu; kan uppgraderas till sqlite-vec/NNS senare).


Verktyg redo f√∂r agent-toolcalling (kb.search/kb.fetch) ‚Äì JSON Schema inkluderat.


Ingestion-fl√∂de s√• du kan fylla KB med dokument snabbt.


Fullt kompatibelt med din Strict-TTS-pipeline och eventloggning.


Perfekt‚Äîh√§r √§r en kompakt, produktionsv√§nlig policy + kodstomme f√∂r din Cloud lane (OpenAI Responses API) som g√∂r att modellen alltid prioriterar kb.search ‚Üí kb.fetch vid faktabaserade fr√•gor, och levererar ett Strict-TTS-kompatibelt AnswerPackage.

1) System-prompt (svenska) ‚Äì ‚ÄúTool-first RAG‚Äù
L√§gg denna som systemmeddelande i din Responses-f√∂rfr√•gan:
Du √§r Alice (svenska). Du f√•r verktyg: kb.search, kb.fetch, timer.set, weather.get.
Regler:
1) Vid faktabaserade/kunskapsfr√•gor (‚Äùvad, n√§r, hur m√•nga, f√∂rklara, k√§lla, visa dokument‚Äù)
   ‚Üí ANV√ÑND ALLTID kb.search f√∂rst, f√∂ljt av kb.fetch p√• relevanta chunkar.
2) Anv√§nd inte paramedvetenhet/magk√§nsla om ett verktyg finns som kan ge fakta.
3) Minimera tokens. Injicera max 25% extern kontext i resonemanget.
4) Svara alltid i strikt JSON enligt `AnswerPackageSchema` (ingen extra text).
5) F√∂r talsvar g√§ller STRICT-TTS: l√§s upp exakt `spoken_text` (eller `ssml` om satt).
6) Vid saknade tr√§ffar: s√§g kort att du inte fann n√•got och be om precisering.

Stil:
- Kort, tydlig, hj√§lpsam, svensk ton. Inga √∂verfl√∂diga ‚Äúfyllnadsfraser‚Äù.
- Om n√•got √§r os√§kert: var explicit (‚Äúos√§kert‚Äù, ‚Äúkan dubbelkolla‚Äù).


2) JSON-schema som tvingar AnswerPackage
Anv√§nd Responses API response_format med JSON Schema s√• att modellen inte kan ‚Äúprata runt‚Äù.
export const AnswerPackageSchema = {
  name: "AnswerPackageSchema",
  schema: {
    type: "object",
    additionalProperties: false,
    properties: {
      spoken_text: { type: "string", minLength: 1 },
      screen_text: { type: "string" },
      ssml:       { type: "string" },
      citations: {
        type: "array",
        items: {
          type: "object",
          additionalProperties: false,
          properties: {
            title: { type: "string" },
            url:   { type: "string" }
          },
          required: ["title"]
        }
      },
      meta: {
        type: "object",
        additionalProperties: true,
        properties: {
          confidence: { type: "number" },
          tone:       { type: "string" }
        }
      }
    },
    required: ["spoken_text"]
  }
} as const;

I anropet:
response_format: { type: "json_schema", json_schema: AnswerPackageSchema }

Om din SDK saknar json_schema, anv√§nd response_format:{ type:"json_object" } som fallback.

3) Tool-preferens (heuristik att ‚Äústyra‚Äù modellen)
L√§gg till som extra systemrad eller ‚Äúpolicy‚Äù:
Tool-policy:
- K√∂r kb.search n√§r fr√•gan r√∂r fakta, dokument, datum, siffror, definitioner, ‚Äúvisa/var/hur‚Äù.
- V√§lj top_k 4‚Äì8. K√∂r kb.fetch p√• 2‚Äì4 b√§st scorade chunkar.
- Sammanfatta KB-inneh√•llet kompakt, undvik dubbletter.
- Anv√§nd weather.get vid v√§derfr√•gor; timer.set f√∂r p√•minnelser/tider.
- Svara inte f√∂rr√§n relevant verktyg anv√§nts eller explicit bed√∂mts on√∂digt.


4) Verktyg (schemas du redan har)
Du har redan JSON-scheman f√∂r kb.search & kb.fetch. Registrera dem i cloud-anropet. Exempelform:
const tools = [
  {
    type: "function",
    name: "kb.search",
    description: "Semantisk s√∂kning i lokal kunskapsbas",
    parameters: require("@/tools/kb.search.schema.json").parameters
  },
  {
    type: "function",
    name: "kb.fetch",
    description: "H√§mta fulltext f√∂r chunkar / metadata f√∂r dokument",
    parameters: require("@/tools/kb.fetch.schema.json").parameters
  },
  // (valfritt) timer.set, weather.get i samma stil
];


5) Minimal Responses-runner (TS) med ‚Äúverktygsslinga‚Äù
Detta √§r en neutral kodstomme (anpassa efter din SDK). Po√§ngen:
skapa response, 2) om tool_calls ‚Üí exekvera lokalt via dina HTTP-endpoints, 3) ‚Äúsubmit tool outputs‚Äù, 4) upprepa tills final.


import OpenAI from "openai"; // el. motsv. Responses-klient
import { AnswerPackageSchema } from "./AnswerPackageSchema";

type ToolCall = { id:string; name:string; arguments:any };

async function callLocalTool(name:string, args:any) {
  const map: Record<string,string> = {
    "kb.search": "/api/tools/kb.search",
    "kb.fetch":  "/api/tools/kb.fetch",
    "timer.set": "/api/tools/timer.set",
    "weather.get": "/api/tools/weather.get"
  };
  const ep = map[name];
  if (!ep) throw new Error(`unknown tool ${name}`);
  const r = await fetch(ep, { method:"POST", headers:{ "content-type":"application/json" }, body: JSON.stringify(args) });
  if (!r.ok) throw new Error(`${name} failed ${r.status}`);
  return await r.json();
}

export async function cloudCompose({
  messages, // [{role:"user"|..."system", content:string}]
  userId, sessionId
}: { messages:any[]; userId:string; sessionId:string }) {

  const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

  // 1) Skapa f√∂rsta svaret
  let resp = await client.responses.create({
    model: process.env.CLOUD_MODEL || "gpt-4o-mini",
    messages,
    tools,
    parallel_tool_calls: false,         // g√∂r ordnad kb.search ‚Üí kb.fetch
    tool_choice: "auto",
    temperature: 0.2,
    response_format: { type: "json_schema", json_schema: AnswerPackageSchema },
    metadata: { userId, sessionId, lane: "cloud" }
  });

  // 2) Loop: k√∂r ev. tools och mata tillbaka resultat
  while (resp.tool_calls?.length) {
    const toolOutputs = [];
    for (const tc of resp.tool_calls as ToolCall[]) {
      const args = typeof tc.arguments === "string" ? JSON.parse(tc.arguments) : tc.arguments;
      const result = await callLocalTool(tc.name, args);
      toolOutputs.push({ tool_call_id: tc.id, output: JSON.stringify(result) });
    }
    // submit tool outputs & forts√§tt
    resp = await client.responses.submitToolOutputs({
      response_id: resp.id,
      tool_outputs: toolOutputs
    });
  }

  // 3) H√§mta slutligt JSON-svar (AnswerPackage)
  const pkg = resp.output_text ? JSON.parse(resp.output_text) : JSON.parse(resp.output[0].content[0].text);
  // validera f√§lt kort:
  if (!pkg?.spoken_text && !pkg?.ssml) throw new Error("invalid AnswerPackage");
  return pkg;
}

Din voice-pipeline kan sedan ropa speakAnswerPackage(tts, pkg) (Strict-TTS).

6) Exempel: hur modellen ‚Äúska‚Äù jobba (demonstration)
L√§gg in en demonstrationskonversation i systemet (hj√§lper modellen f√∂lja policy):
Exempel (tool-first):
User: ‚ÄúVad g√∂r Alice och varifr√•n kommer dokumentationen?‚Äù
Assistant: (kallar kb.search { query:"Alice dokumentation" } ‚Üí tr√§ffar)
Assistant: (kallar kb.fetch { chunk_ids:["...","..."] } ‚Üí f√•r text)
Assistant: (returnerar AnswerPackage JSON med kort sammanfattning + ev. citations[])


7) Telemetri (minsta)
Logga i din EventBus:
tool_call { name, args_hash, t_start }


tool_result { name, ms, size }


cloud_pkg { e2e_ms, injected_tokens_pct?, used_tools:["kb.search","kb.fetch"] }



8) Latens-tips f√∂r RAG-f√∂rsta-mening
H√•ll parallel_tool_calls:false s√• kb.search ‚Üí kb.fetch sker i ordning.


K√∂r sentence streaming i lokal lane (FAS 7) f√∂r att b√∂rja l√§sa f√∂rsta meningen n√§r pkg finns.


S√§tt deadline i din fallback (t.ex. 1500 ms) ‚Äì om cloud dr√∂jer: anv√§nd lokal/OSS lane f√∂r f√∂rsta mening + komplettera.



Snabb ‚Äúplug-in‚Äù i din nuvarande kod
L√§gg in System-prompt + AnswerPackageSchema + tools i din cloud-adapter.


Byt din nuvarande /api/agent cloud-kod mot runnern ovan (eller mata in dess k√§rna).


Se till att kb.search/kb.fetch endpoints finns (du har dem).


Koppla Strict-TTS p√• resultatet.


Kort svar: vi √§r i mycket bra shape f√∂r demo/pilot (r√∂st ‚áÑ agent ‚áÑ tools + lokal RAG). F√∂r att k√§nna oss helt ‚Äúklara‚Äù saknas bara n√•gra sm√• men viktiga limbitar. H√§r √§r min korta gap-lista + vad jag skulle l√§gga till direkt:
Vad som saknas (sm√• ‚Äúglue‚Äù-bitar)
Input-validering √∂verallt
 L√§gg Zod (eller liknande) p√•: /api/brain/compose, /api/memory/*, /api/tools/kb.*, /api/agent. Returnera 400 + felorsak.
 ‚Üí Minskar edge-case krascher.


Abort & backpressure end-to-end
 Barge-in ska alltid: tts.cancel() ‚Üí abortera p√•g√•ende fetch('/api/brain/compose', {signal}) ‚Üí stoppa ev. cloud-k√∂rning.
 ‚Üí Du har barge-in i pipen; s√§kerst√§ll att abort bubblar hela v√§gen.


Retries + idempotens f√∂r tools
 Exponential backoff (jitter) f√∂r enkla n√§tverksfel. Idempotency-key i timer.set (och framtida muterande verktyg).
 ‚Üí Undviker dubletter och ‚Äúsp√∂k-timers‚Äù.


Metrics-aggregator (p50/p95) + correlationId
 Du loggar NDJSON; addera en enkel /api/metrics/summary (p50/p95/p99) och ett correlation_id per tur.
 ‚Üí Snabb fels√∂kning i drift.


Embeddings ‚Äúp√• riktigt‚Äù (senare ‚Äì enkelt byte)
 Vi k√∂r stub nu (OK f√∂r start). L√§gg ett interface f√∂r embed() och flagga:


EMBED_PROVIDER=local (bge-small/onnx/WebGPU) eller openai (text-embedding-3-small).


Aktivera sqlite-vec n√§r du vill ha ANN p√• riktigt.
 ‚Üí G√∂r RAG kvalitativt utan att √§ndra API.


PromptBuilder & injektionsbudget
 L√§gg persona.yml + style.yml (faktiskt inneh√•ll) och h√•ll INJECT_BUDGET_PCT ‚â§ 25%. Logga injected_tokens_pct.
 ‚Üí Stabil persona + token-disciplin.


S√§kerhets-hygien & CORS


CORS allowlist (din dom√§n),


inga hemligheter i NEXT_PUBLIC_*,


strikta headers (du har det delvis).
 ‚Üí Sm√• men viktiga.


TTL & st√§d
 Liten worker/cron f√∂r att rensa expires_at, rotera logs/metrics.ndjson, VACUUM ibland.
 ‚Üí H√•ller SQLite och loggar fr√§scha.


Health-probes f√∂r hj√§rnan
 /api/health b√∂r √§ven testa: compose-hot-path (snabb synthetic prompt ‚Üí 200).
 ‚Üí Ser direkt om ‚ÄúBrain lane‚Äù √§r vaken.


Tests som matchar v√•ra DoD


strict-tts: TTS == spoken_text/ssml


fallback under deadline


RAG-s√∂k ‚Üí fetch ‚Üí svar (golden).
 ‚Üí L√•gt underh√•ll, h√∂g trygghet.


Go/No-Go snabbmatris
‚úÖ R√∂st E2E + toolcalling: OK


‚úÖ Lokal KB/RAG v1: OK (JS-cosine nu, uppgradera till sqlite-vec senare)


‚úÖ Cloud lane (Responses API + tool-first RAG): OK


‚¨ú Abort & retries & input-zod: G√∂rs nu (l√§tt)


‚¨ú PromptBuilder inneh√•ll + budget-logg: G√∂rs nu


‚¨ú Metrics-summary + correlationId: G√∂rs nu


N√§r dessa tre rutor √§r gr√∂na √§r vi ‚Äúproduction-comfortable‚Äù f√∂r din anv√§ndning.
Direkt att g√∂ra (konkret i denna ordning)
L√§gg Zod-validering p√• alla POST-routes.


Koppla AbortController vidare till brain/agent + anv√§nd tts.cancel() vid barge-in.


Sl√• p√• retries (med jitter) och idempotency-key i muterande tool-calls.


L√§gg /api/metrics/summary + correlation_id per turn.


Fyll persona.yml & style.yml, aktivera buildContext() med 25% budget.


(Valfritt nu / senare) Byt embed() till riktig modell; aktivera sqlite-vec.


Nice-to-have f√∂r n√§sta sprint
Sentence streaming (f√∂rsta meningen snabbare i tal).


Vision lane (YOLO+SAM) ‚Üí vision_event ‚Üí justera tonl√§ge.


EmotionEngine ‚Üí SSML/prosodi (svenskt tal k√§nns markant b√§ttre).


Camera/HA tools (snapshot/ptz + HA sub).



