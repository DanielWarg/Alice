âœ…âŒ Alice Roadmap 2025â€“2026 (Checklist Edition)
Phase B â€” Robust Core (2025 H1)

B1 Local Fast Lane (**REIMPLEMENTING WITH NEW ARCHITECTURE**)

### **ğŸ™ï¸ New Streaming Voice Pipeline (Sub-500ms Target)**

**ğŸ“ Infrastructure & Transport**
âœ… Scaffold WebSocket/DataChannel server + binary audio frames
âœ… Client mic capture â†’ 20ms frames with VAD (WebRTC-VAD aggressiveness=2)
âœ… Jitter buffer (100ms) & playback with cross-fade (80ms)
âœ… Audio ducking (-18dB when TTS active) and echo cancellation

**ğŸ¯ ASR Streaming (faster-whisper)**
â¬œ faster-whisper adapter with streaming configuration
â¬œ Partial transcription â‰¤200ms, final on silence â‰¥250ms
â¬œ chunk_ms=200, stabilize_ms=250, beam_size=1, no_speech_threshold=0.6
â¬œ Event emission: `partial(text)`, `final(text)` with timestamps

**ğŸ§  LLM Streaming (gpt-oss 7B)**
â¬œ gpt-oss 7B Q4_K_M streaming adapter 
â¬œ First token emission â‰¤300ms target
â¬œ max_new_tokens=40, temperature=0.2, top_p=0.9, stream=true
â¬œ System prompt: "Spoken style, â‰¤2 sentences, concise"

**ğŸ”Š TTS Streaming (Piper)**
â¬œ Pre-warmed Piper model (synthesize 100ms silence on boot)
â¬œ Stream 40-80ms PCM chunks, first chunk â‰¤150ms
â¬œ Phrase splitter: 10-25 words or minor punctuation triggers
â¬œ Cancel with 80-120ms smooth ramp-down (no clicks)

**âš¡ Barge-in System**
â¬œ Client VAD detection during playback â†’ `barge_in` signal
â¬œ Server cancels TTS with smooth fadeout <120ms
â¬œ Measure and log `barge_in_cut_ms` for performance tracking
â¬œ Resume-safe: spurious barge-in doesn't resume old TTS

**ğŸµ Micro-acks & Responsiveness**
â¬œ Pre-baked PCM acks ("Mm?" ~180ms) on first partial (â‰¥2 words)
â¬œ Auto cross-fade out when first Piper chunk arrives
â¬œ Perceived responsiveness without waiting for full LLM response

**ğŸ§­ Router & Privacy Architecture**
â¬œ Intelligent routing: `local_fast` (default) vs `cloud_complex` (opt-in)
â¬œ Heuristics: PII/tools/long-tokens â†’ route appropriately
â¬œ Safe-Summary privacy gate: 1-2 sentences, â‰¤300 chars, no PII
â¬œ Timeout guard: cloud TTFA >600ms twice â†’ lock cloud 5 min

**ğŸ“Š Telemetry & Diagnostics**
â¬œ Real-time NDJSON metrics: first_partial_ms, ttft_ms, tts_first_chunk_ms
â¬œ total_latency_ms, barge_in_cut_ms, privacy_leak_attempts tracking
â¬œ `/diagnostics` UI panel showing p50/p95 performance live
â¬œ Self-test integration with latency/barge-in/privacy validation

**ğŸ§ª Comprehensive Testing Suite**
â¬œ 50 short utterances p95 â‰¤500ms latency validation
â¬œ 20 barge-in tests <120ms cut, no audible clicks
â¬œ 0 privacy leaks in synthetic tool prompts with PII
â¬œ Full offline `local_fast` operation without network
â¬œ Loopback echo prevention (energy <-12dB with AEC+ducking)

B2 Tool Lane & Memory

âœ… Local tools (Gmail, Calendar, Files, Home) stubs

âœ… Privacy filter â†’ Safe Summary (no PII)

âœ… SQLite episodic memory + sqlite-vec embeddings

â¬œ Retention controls (Forget Now/Today/All)

â¬œ UI badges (â€œCloud usedâ€, â€œAll localâ€, â€œWhat was spoken?â€)

B3 Self-Tests & Packaging

âœ… start_alice.sh autonom self-test runner (quick/full/ci)

âœ… Self-test blocks boot on fail, logs artifacts (NDJSON/JUnit)

âœ… Deterministic installs (npm ci, pip hashes, PID files)

â¬œ Electron app packaging with auto-update & signing

â¬œ Model Manager (manifest, checksums, resumable downloads)

Phase C â€” Cutting Edge Expansion (2025 H2)

C1 Cloud â€œComplex Laneâ€ (optional)

â¬œ Responses API integration for reasoning + tools

â¬œ Reasoning summaries visible in UI/logs

â¬œ Background tasks with safe_summary outputs

â¬œ Network-guard blocks no_cloud payloads

C2 MCP Standardization

â¬œ Wrap Calendar, Email, Files, Home as MCP servers

â¬œ Engine MCP client integration

C3 Vision Lane

â¬œ RTSP ingest â†’ WebRTC for network cameras

â¬œ YOLOv10-S/N (Metal) real-time detection

â¬œ SAM-2 for segmentation/tracking bursts

â¬œ Zone rules â†’ Engine events

â¬œ Ephemeral re-ID, auto-forget

C4 Persona / Media

â¬œ HeyGen Streaming Avatar integration (safe_summary only)

â¬œ LiveKit transport (optional showcase path)

Phase D â€” Self-Learning â€œPattern LLMâ€ (2025 H2â€“2026 H1)

D1 Pattern LLM v0 (shadow mode)

â¬œ Tiny local LLM (50â€“200M params, 4-bit) scorer

â¬œ Event featurizer â†’ compact tokens

â¬œ Outputs: P(next_action), P(accept), etc.

â¬œ Bandit layer (LinUCB/TS) integration

â¬œ Shadow mode logging (no suggestions shown)

D2 Pattern LLM v1 (online learning)

â¬œ On-device LoRA/adapters or calibrated heads

â¬œ Throttled online updates

â¬œ Intervention budget (max 3/day, accept-rate â‰¥30%)

â¬œ User controls: Off / Learn / Forget week / Forget all

D3 RL-Light (assist-only)

â¬œ Offline RL (IQL/CQL small) from logs

â¬œ Conservative assist-only policies (propose, not execute)

â¬œ Safety bounds, rollback on low reward

Phase E â€” Portability & Multi-Shell (2026 H1)

â¬œ Desktop (Electron v1, later Tauri)

â¬œ Mobile (React Native shell)

â¬œ Web (PWA shell)

â¬œ Shared Engine API (HTTP/WS, Talk socket)

â¬œ Export/Import encrypted ZIP for memory + Pattern LLM state

Cross-Cutting

âœ… Safe Summary-only to external voice/cloud

âœ… Network-guard for no_cloud payloads

âœ… Secrets in OS keyring; metrics-only logs

â¬œ Observability panel (latency charts, leak counter, p95 SLOs)

â¬œ Auto-update pipeline for app + models

Next actionable steps

â¬œ Retention controls in memory (Forget Now/Today/All).

â¬œ Electron packaging + auto-update for Alice desktop.

â¬œ Model Manager (manifest + resumable downloads).