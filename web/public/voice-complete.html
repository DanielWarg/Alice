<!DOCTYPE html>
<html lang="sv">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice v2 Complete Test</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 30px;
            backdrop-filter: blur(10px);
        }
        
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
        }
        
        .voice-section {
            margin: 20px 0;
            padding: 25px;
            background: rgba(255, 255, 255, 0.08);
            border-radius: 15px;
        }
        
        .mic-button {
            background: linear-gradient(45deg, #ff4757, #ff6348);
            border: none;
            color: white;
            padding: 25px;
            border-radius: 50%;
            font-size: 32px;
            cursor: pointer;
            width: 100px;
            height: 100px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 20px auto;
            transition: all 0.3s ease;
        }
        
        .mic-button:hover {
            transform: scale(1.05);
        }
        
        .mic-button.recording {
            background: linear-gradient(45deg, #e74c3c, #c0392b);
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            font-weight: bold;
        }
        
        .status.success { background: rgba(76, 175, 80, 0.2); }
        .status.error { background: rgba(244, 67, 54, 0.2); }
        .status.warning { background: rgba(255, 152, 0, 0.2); }
        
        .transcript, .response {
            background: rgba(0, 0, 0, 0.2);
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            font-size: 16px;
            min-height: 50px;
        }
        
        .response {
            background: rgba(46, 204, 113, 0.2);
        }
        
        audio {
            width: 100%;
            margin: 15px 0;
        }
        
        .log {
            max-height: 200px;
            overflow-y: auto;
            background: rgba(0, 0, 0, 0.3);
            padding: 15px;
            border-radius: 10px;
            font-family: monospace;
            font-size: 12px;
        }
        
        button {
            background: linear-gradient(45deg, #5dade2, #3498db);
            border: none;
            color: white;
            padding: 12px 24px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Alice Voice Assistant</h1>
        <p style="text-align: center; color: rgba(255,255,255,0.8); margin-bottom: 20px;">
            üá∏üá™ ‚Üí üá∫üá∏ Speak Swedish, Alice responds in English
        </p>
        
        <div class="voice-section">
            <button class="mic-button" id="micButton" onclick="toggleRecording()">
                üé§
            </button>
            <div id="status" class="status">Klicka p√• mikrofonen f√∂r att b√∂rja</div>
        </div>

        <div class="voice-section">
            <h3>Bilingual Conversation</h3>
            <div class="transcript" id="transcript">Du sa (Swedish): ...</div>
            <div class="response" id="response">Alice responds (English): ...</div>
            <audio id="audio" controls></audio>
        </div>

        <div class="voice-section">
            <h3>Alice TTS Tests (English Voice)</h3>
            <button onclick="testTTS('Hello! I\\'m Alice, your Swedish-English voice assistant.')">Test Greeting</button>
            <button onclick="testTTS('You have 3 new messages and 1 important notification.')">Test Email</button>
            <button onclick="testTTS('The current weather in Stockholm is 18 degrees with sunny conditions.')">Test Weather</button>
            <button onclick="testTTS('I\\'m turning on all the smart lights in your home now.')">Test Smart Home</button>
        </div>

        <div class="voice-section">
            <h3>Systemlogg</h3>
            <div id="log" class="log">Startar Voice v2 system...<br></div>
        </div>
    </div>

    <script>
        let recognition;
        let isRecording = false;
        
        function log(message) {
            const logEl = document.getElementById('log');
            const time = new Date().toLocaleTimeString();
            logEl.innerHTML += `[${time}] ${message}<br>`;
            logEl.scrollTop = logEl.scrollHeight;
        }
        
        function updateStatus(message, type = 'success') {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = `status ${type}`;
        }
        
        // Initialize Speech Recognition
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
            } else if ('SpeechRecognition' in window) {
                recognition = new SpeechRecognition();
            } else {
                log('‚ùå Speech recognition inte st√∂dd');
                updateStatus('Speech recognition inte tillg√§nglig', 'error');
                return false;
            }

            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'sv-SE'; // Swedish

            recognition.onstart = function() {
                log('üé§ Lyssnar...');
                updateStatus('Talar nu!', 'warning');
            };

            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                log(`üó£Ô∏è Du sa: "${transcript}"`);
                document.getElementById('transcript').textContent = `Du sa: "${transcript}"`;
                processVoiceCommand(transcript);
            };

            recognition.onerror = function(event) {
                log(`‚ùå Speech error: ${event.error}`);
                updateStatus(`Fel: ${event.error}`, 'error');
                resetMic();
            };

            recognition.onend = function() {
                resetMic();
            };

            return true;
        }
        
        function toggleRecording() {
            if (!recognition) {
                updateStatus('Speech recognition inte tillg√§nglig', 'error');
                return;
            }

            if (isRecording) {
                recognition.stop();
            } else {
                recognition.start();
                isRecording = true;
                document.getElementById('micButton').classList.add('recording');
            }
        }
        
        function resetMic() {
            isRecording = false;
            document.getElementById('micButton').classList.remove('recording');
            updateStatus('Klicka p√• mikrofonen f√∂r att b√∂rja', 'success');
        }
        
        async function processVoiceCommand(text) {
            updateStatus('Alice analyserar intent...', 'warning');
            log(`üß† Bearbetar med NLU: "${text}"`);
            
            try {
                // Call NLU Intent Classification API
                const nluResponse = await fetch('http://localhost:8000/api/nlu/classify', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        text: text
                    })
                });
                
                let intent = null;
                if (nluResponse.ok) {
                    intent = await nluResponse.json();
                    log(`üéØ Intent: ${intent.category}/${intent.action} (conf: ${intent.confidence.toFixed(2)})`);
                    if (intent.entities && Object.keys(intent.entities).length > 0) {
                        log(`üîç Entities: ${JSON.stringify(intent.entities)}`);
                    }
                } else {
                    log(`‚ùå NLU fel: ${nluResponse.status}`);
                }
                
                // Generate response based on intent
                let response = await generateSmartResponse(text, intent);
                
                document.getElementById('response').textContent = `Alice: ${response}`;
                log(`ü§ñ Alice svarar: "${response}"`);
                
                // Convert to speech
                await testTTS(response);
                updateStatus('Konversation klar!', 'success');
                
            } catch (error) {
                log(`‚ùå Fel vid bearbetning: ${error}`);
                updateStatus('Kunde inte bearbeta kommando', 'error');
            }
        }
        
        async function generateSmartResponse(text, intent) {
            // TEMPORARY: Use intelligent fallback responses (RAG system not configured)
            console.log('üß† Using intelligent fallback (RAG not configured):', { text, intent });
            return generateIntelligentFallback(text, intent);
        }
        
        function generateIntelligentFallback(text, intent) {
            // Intelligent fallback responses (better than basic mock)
            const currentTime = new Date().toLocaleTimeString('en-US', { 
                hour12: false, 
                hour: '2-digit', 
                minute: '2-digit' 
            });
            const currentDate = new Date().toLocaleDateString('en-US', { 
                weekday: 'long',
                year: 'numeric', 
                month: 'long', 
                day: 'numeric' 
            });
            
            if (!intent || intent.category === 'unknown') {
                return `I heard you say "${text}" in Swedish. I understand you perfectly, but I need a bit more context to provide the best response. Could you rephrase your request?`;
            }
            
            switch (intent.category) {
                case 'communication':
                    if (intent.action === 'check_email') {
                        return 'I understand you want to check your email. Your email system is configured and ready - you have several new messages waiting. Would you like me to read the most important ones first?';
                    } else if (intent.action === 'call') {
                        const person = intent.entities?.person_name || 'your contact';
                        return `I'm initiating a call to ${person} now. The system is connecting... Please wait while I establish the connection through your communication system.`;
                    }
                    return 'I\'m handling your communication request through the integrated messaging system. Everything is set up and ready to process your request.';
                    
                case 'time':
                    if (intent.action === 'current_time') {
                        return `The current time is ${currentTime} on ${currentDate}. Your schedule system is synchronized and running perfectly. Is there anything specific you need to plan?`;
                    } else if (intent.action === 'schedule') {
                        const date = intent.entities?.date || 'your requested time';
                        return `I'm creating a calendar entry for ${date}. Your scheduling system is active and I've successfully added this to your calendar. You'll receive a notification when the time approaches.`;
                    }
                    return `Current time: ${currentTime}. Your time management system is fully operational and synchronized across all your devices.`;
                    
                case 'weather':
                    return 'I understand you want weather information. Based on current conditions in your area, the weather system is operational and monitoring local conditions. The forecast shows generally stable conditions with normal seasonal patterns expected.';
                    
                case 'system':
                    if (intent.action === 'lights_on') {
                        return 'I\'m activating all smart lights in your home now. The lighting control system has responded successfully - all connected lights are now on and functioning at optimal levels.';
                    } else if (intent.action === 'lights_off') {
                        return 'I\'m turning off all smart lights throughout your home. The lighting system has processed the command successfully - all connected devices are now in standby mode.';
                    }
                    return 'Your smart home command is being processed through the central control system. All connected devices are responding normally and the network is stable.';
                    
                case 'greeting':
                    if (intent.action === 'hello') {
                        return `Hello there! I'm Alice, and I'm functioning perfectly. The time is ${currentTime} and all my systems are running smoothly. I understand Swedish fluently but respond in English for optimal clarity. How may I assist you today?`;
                    } else if (intent.action === 'how_are_you') {
                        return 'I\'m operating at full capacity! My voice recognition, language processing, and response systems are all functioning excellently. I understand Swedish perfectly and I\'m ready to help with any task you have in mind.';
                    }
                    return `Hello! I'm Alice, your voice assistant. Current time is ${currentTime} and I understand your Swedish input perfectly. My systems are fully operational - what would you like me to help you with?`;
                    
                default:
                    return `I identified your intent as "${intent.category}" and I'm processing that through my understanding systems. While I analyze the best way to help you, could you provide any additional details about what specifically you need?`;
            }
        }
        
        async function testTTS(text) {
            log(`üîä TTS: "${text}"`);
            
            try {
                const response = await fetch('http://localhost:8000/api/tts/', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        text: text,
                        voice: 'nova',
                        rate: 1.0
                    })
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}`);
                }
                
                const data = await response.json();
                log(`‚úÖ TTS (${data.processing_time_ms?.toFixed(1)}ms): ${data.cached ? 'cached' : 'generated'}`);
                
                // Play audio - try multiple approaches
                const audio = document.getElementById('audio');
                const audioUrl = `http://localhost:8000${data.url}`;
                log(`üîó Setting audio source: ${audioUrl}`);
                
                // Method 1: Try direct audio element approach
                try {
                    // First try to fetch the audio as blob to verify it's accessible
                    const audioResponse = await fetch(audioUrl, {
                        method: 'GET',
                        headers: {
                            'Accept': 'audio/mpeg,audio/*'
                        }
                    });
                    
                    if (!audioResponse.ok) {
                        throw new Error(`HTTP ${audioResponse.status}`);
                    }
                    
                    const contentType = audioResponse.headers.get('content-type');
                    log(`üîç Audio content-type: ${contentType}`);
                    
                    const arrayBuffer = await audioResponse.arrayBuffer();
                    log(`üì¶ Audio size: ${arrayBuffer.byteLength} bytes`);
                    
                    // Create blob URL
                    const blob = new Blob([arrayBuffer], { type: contentType || 'audio/mpeg' });
                    const blobUrl = URL.createObjectURL(blob);
                    log(`üîó Created blob URL: ${blobUrl.substring(0, 50)}...`);
                    
                    // Set audio source to blob URL
                    audio.src = blobUrl;
                    audio.load();
                    
                    // Wait for ready
                    await new Promise((resolve, reject) => {
                        const timeout = setTimeout(() => reject(new Error('Audio load timeout')), 5000);
                        
                        audio.addEventListener('loadeddata', () => {
                            clearTimeout(timeout);
                            log('‚ñ∂Ô∏è Audio ready to play');
                            resolve();
                        });
                        
                        audio.addEventListener('error', (e) => {
                            clearTimeout(timeout);
                            const error = e.target.error;
                            log(`‚ùå Audio load error: ${error?.code} - ${error?.message}`);
                            reject(new Error(`Audio load error: ${error?.message || 'Unknown'}`));
                        });
                    });
                    
                    // Try to play
                    await audio.play();
                    log('üéµ Spelar ljud via blob');
                    
                    // Clean up blob URL
                    setTimeout(() => URL.revokeObjectURL(blobUrl), 10000);
                    
                } catch (audioError) {
                    log(`‚ùå Audio blob method failed: ${audioError.message}`);
                    
                    // Method 2: Fallback to direct URL
                    try {
                        audio.src = audioUrl;
                        audio.load();
                        await audio.play();
                        log('üéµ Spelar ljud via direct URL');
                    } catch (fallbackError) {
                        log(`‚ùå Audio direct method failed: ${fallbackError.message}`);
                        log('‚ÑπÔ∏è Manual playback required - click the play button');
                    }
                }
                
            } catch (error) {
                log(`‚ùå TTS fel: ${error}`);
            }
        }
        
        // Initialize on load
        document.addEventListener('DOMContentLoaded', function() {
            log('üöÄ Startar Voice v2 system...');
            
            if (initSpeechRecognition()) {
                log('‚úÖ Speech recognition redo');
                updateStatus('Klicka p√• mikrofonen f√∂r att b√∂rja', 'success');
            }
            
            // Test backend
            fetch('http://localhost:8000/health')
                .then(response => response.json())
                .then(data => {
                    log(`‚úÖ Backend ansluten: ${data.service}`);
                })
                .catch(error => {
                    log(`‚ùå Backend fel: ${error}`);
                });
        });
        
        log('üí° Tips: S√§g "Kolla min email", "Vad √§r klockan" eller "Hej Alice"');
    </script>
</body>
</html>