<!DOCTYPE html>
<html lang="sv">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice v2 Complete Test</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 30px;
            backdrop-filter: blur(10px);
        }
        
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
        }
        
        .voice-section {
            margin: 20px 0;
            padding: 25px;
            background: rgba(255, 255, 255, 0.08);
            border-radius: 15px;
        }
        
        .mic-button {
            background: linear-gradient(45deg, #ff4757, #ff6348);
            border: none;
            color: white;
            padding: 25px;
            border-radius: 50%;
            font-size: 32px;
            cursor: pointer;
            width: 100px;
            height: 100px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 20px auto;
            transition: all 0.3s ease;
        }
        
        .mic-button:hover {
            transform: scale(1.05);
        }
        
        .mic-button.recording {
            background: linear-gradient(45deg, #e74c3c, #c0392b);
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            font-weight: bold;
        }
        
        .status.success { background: rgba(76, 175, 80, 0.2); }
        .status.error { background: rgba(244, 67, 54, 0.2); }
        .status.warning { background: rgba(255, 152, 0, 0.2); }
        
        .transcript, .response {
            background: rgba(0, 0, 0, 0.2);
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            font-size: 16px;
            min-height: 50px;
        }
        
        .response {
            background: rgba(46, 204, 113, 0.2);
        }
        
        audio {
            width: 100%;
            margin: 15px 0;
        }
        
        .log {
            max-height: 200px;
            overflow-y: auto;
            background: rgba(0, 0, 0, 0.3);
            padding: 15px;
            border-radius: 10px;
            font-family: monospace;
            font-size: 12px;
        }
        
        button {
            background: linear-gradient(45deg, #5dade2, #3498db);
            border: none;
            color: white;
            padding: 12px 24px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Voice v2 Test</h1>
        
        <div class="voice-section">
            <button class="mic-button" id="micButton" onclick="toggleRecording()">
                üé§
            </button>
            <div id="status" class="status">Klicka p√• mikrofonen f√∂r att b√∂rja</div>
        </div>

        <div class="voice-section">
            <h3>Konversation</h3>
            <div class="transcript" id="transcript">Du sa: ...</div>
            <div class="response" id="response">Alice svarar: ...</div>
            <audio id="audio" controls></audio>
        </div>

        <div class="voice-section">
            <h3>Snabbtester</h3>
            <button onclick="testTTS('Hej, hur m√•r du?')">Test TTS</button>
            <button onclick="testTTS('Kolla min email')">Test Email</button>
            <button onclick="testTTS('Vad √§r klockan?')">Test Tid</button>
        </div>

        <div class="voice-section">
            <h3>Systemlogg</h3>
            <div id="log" class="log">Startar Voice v2 system...<br></div>
        </div>
    </div>

    <script>
        let recognition;
        let isRecording = false;
        
        function log(message) {
            const logEl = document.getElementById('log');
            const time = new Date().toLocaleTimeString();
            logEl.innerHTML += `[${time}] ${message}<br>`;
            logEl.scrollTop = logEl.scrollHeight;
        }
        
        function updateStatus(message, type = 'success') {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = `status ${type}`;
        }
        
        // Initialize Speech Recognition
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
            } else if ('SpeechRecognition' in window) {
                recognition = new SpeechRecognition();
            } else {
                log('‚ùå Speech recognition inte st√∂dd');
                updateStatus('Speech recognition inte tillg√§nglig', 'error');
                return false;
            }

            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'sv-SE'; // Swedish

            recognition.onstart = function() {
                log('üé§ Lyssnar...');
                updateStatus('Talar nu!', 'warning');
            };

            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                log(`üó£Ô∏è Du sa: "${transcript}"`);
                document.getElementById('transcript').textContent = `Du sa: "${transcript}"`;
                processVoiceCommand(transcript);
            };

            recognition.onerror = function(event) {
                log(`‚ùå Speech error: ${event.error}`);
                updateStatus(`Fel: ${event.error}`, 'error');
                resetMic();
            };

            recognition.onend = function() {
                resetMic();
            };

            return true;
        }
        
        function toggleRecording() {
            if (!recognition) {
                updateStatus('Speech recognition inte tillg√§nglig', 'error');
                return;
            }

            if (isRecording) {
                recognition.stop();
            } else {
                recognition.start();
                isRecording = true;
                document.getElementById('micButton').classList.add('recording');
            }
        }
        
        function resetMic() {
            isRecording = false;
            document.getElementById('micButton').classList.remove('recording');
            updateStatus('Klicka p√• mikrofonen f√∂r att b√∂rja', 'success');
        }
        
        async function processVoiceCommand(text) {
            updateStatus('Alice analyserar intent...', 'warning');
            log(`üß† Bearbetar med NLU: "${text}"`);
            
            try {
                // Call NLU Intent Classification API
                const nluResponse = await fetch('http://localhost:8000/api/nlu/classify', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        text: text
                    })
                });
                
                let intent = null;
                if (nluResponse.ok) {
                    intent = await nluResponse.json();
                    log(`üéØ Intent: ${intent.category}/${intent.action} (conf: ${intent.confidence.toFixed(2)})`);
                    if (intent.entities && Object.keys(intent.entities).length > 0) {
                        log(`üîç Entities: ${JSON.stringify(intent.entities)}`);
                    }
                } else {
                    log(`‚ùå NLU fel: ${nluResponse.status}`);
                }
                
                // Generate response based on intent
                let response = await generateSmartResponse(text, intent);
                
                document.getElementById('response').textContent = `Alice: ${response}`;
                log(`ü§ñ Alice svarar: "${response}"`);
                
                // Convert to speech
                await testTTS(response);
                updateStatus('Konversation klar!', 'success');
                
            } catch (error) {
                log(`‚ùå Fel vid bearbetning: ${error}`);
                updateStatus('Kunde inte bearbeta kommando', 'error');
            }
        }
        
        async function generateSmartResponse(text, intent) {
            // Generate contextual responses based on intent
            if (!intent || intent.category === 'unknown') {
                return `Du sa "${text}". Jag f√∂rstod inte riktigt - kan du formulera om det?`;
            }
            
            switch (intent.category) {
                case 'communication':
                    if (intent.action === 'check_email') {
                        return 'Du har 3 nya email och 1 viktigt meddelande.';
                    } else if (intent.action === 'call') {
                        const person = intent.entities?.person_name || 'kontakt';
                        return `Ringer till ${person}... Tyv√§rr, ingen svarar just nu.`;
                    }
                    return 'Hanterar kommunikation...';
                    
                case 'time':
                    if (intent.action === 'current_time') {
                        const now = new Date().toLocaleTimeString('sv-SE');
                        return `Klockan √§r ${now}.`;
                    } else if (intent.action === 'schedule') {
                        const date = intent.entities?.date || 'senare';
                        return `S√§tter p√•minnelse f√∂r ${date}. P√•minnelsen √§r sparad!`;
                    }
                    return 'Hanterar tid och schema...';
                    
                case 'weather':
                    return 'Det √§r 18 grader och soligt i Stockholm idag. L√§tt molnighet p√• eftermiddagen.';
                    
                case 'system':
                    if (intent.action === 'lights_on') {
                        return 'T√§nder lamporna... Alla lampor √§r nu p√•.';
                    } else if (intent.action === 'lights_off') {
                        return 'Sl√§cker lamporna... Alla lampor √§r nu avst√§ngda.';
                    }
                    return 'Utf√∂r systemkommando...';
                    
                case 'greeting':
                    if (intent.action === 'hello') {
                        return 'Hej! Jag m√•r bra, tack f√∂r att du fr√•gar. Hur kan jag hj√§lpa dig idag?';
                    } else if (intent.action === 'how_are_you') {
                        return 'Jag m√•r utm√§rkt! Mitt Whisper ASR och NLU system fungerar perfekt. Vad kan jag hj√§lpa till med?';
                    }
                    return 'Hej! Vad kan jag hj√§lpa dig med?';
                    
                default:
                    return `Jag identifierade "${intent.category}" intent men vet inte hur jag ska hantera det √§n.`;
            }
        }
        
        async function testTTS(text) {
            log(`üîä TTS: "${text}"`);
            
            try {
                const response = await fetch('http://localhost:8000/api/tts/', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        text: text,
                        voice: 'nova',
                        rate: 1.0
                    })
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}`);
                }
                
                const data = await response.json();
                log(`‚úÖ TTS (${data.processing_time_ms?.toFixed(1)}ms): ${data.cached ? 'cached' : 'generated'}`);
                
                // Play audio - try multiple approaches
                const audio = document.getElementById('audio');
                const audioUrl = `http://localhost:8000${data.url}`;
                log(`üîó Setting audio source: ${audioUrl}`);
                
                // Method 1: Try direct audio element approach
                try {
                    // First try to fetch the audio as blob to verify it's accessible
                    const audioResponse = await fetch(audioUrl, {
                        method: 'GET',
                        headers: {
                            'Accept': 'audio/mpeg,audio/*'
                        }
                    });
                    
                    if (!audioResponse.ok) {
                        throw new Error(`HTTP ${audioResponse.status}`);
                    }
                    
                    const contentType = audioResponse.headers.get('content-type');
                    log(`üîç Audio content-type: ${contentType}`);
                    
                    const arrayBuffer = await audioResponse.arrayBuffer();
                    log(`üì¶ Audio size: ${arrayBuffer.byteLength} bytes`);
                    
                    // Create blob URL
                    const blob = new Blob([arrayBuffer], { type: contentType || 'audio/mpeg' });
                    const blobUrl = URL.createObjectURL(blob);
                    log(`üîó Created blob URL: ${blobUrl.substring(0, 50)}...`);
                    
                    // Set audio source to blob URL
                    audio.src = blobUrl;
                    audio.load();
                    
                    // Wait for ready
                    await new Promise((resolve, reject) => {
                        const timeout = setTimeout(() => reject(new Error('Audio load timeout')), 5000);
                        
                        audio.addEventListener('loadeddata', () => {
                            clearTimeout(timeout);
                            log('‚ñ∂Ô∏è Audio ready to play');
                            resolve();
                        });
                        
                        audio.addEventListener('error', (e) => {
                            clearTimeout(timeout);
                            const error = e.target.error;
                            log(`‚ùå Audio load error: ${error?.code} - ${error?.message}`);
                            reject(new Error(`Audio load error: ${error?.message || 'Unknown'}`));
                        });
                    });
                    
                    // Try to play
                    await audio.play();
                    log('üéµ Spelar ljud via blob');
                    
                    // Clean up blob URL
                    setTimeout(() => URL.revokeObjectURL(blobUrl), 10000);
                    
                } catch (audioError) {
                    log(`‚ùå Audio blob method failed: ${audioError.message}`);
                    
                    // Method 2: Fallback to direct URL
                    try {
                        audio.src = audioUrl;
                        audio.load();
                        await audio.play();
                        log('üéµ Spelar ljud via direct URL');
                    } catch (fallbackError) {
                        log(`‚ùå Audio direct method failed: ${fallbackError.message}`);
                        log('‚ÑπÔ∏è Manual playback required - click the play button');
                    }
                }
                
            } catch (error) {
                log(`‚ùå TTS fel: ${error}`);
            }
        }
        
        // Initialize on load
        document.addEventListener('DOMContentLoaded', function() {
            log('üöÄ Startar Voice v2 system...');
            
            if (initSpeechRecognition()) {
                log('‚úÖ Speech recognition redo');
                updateStatus('Klicka p√• mikrofonen f√∂r att b√∂rja', 'success');
            }
            
            // Test backend
            fetch('http://localhost:8000/health')
                .then(response => response.json())
                .then(data => {
                    log(`‚úÖ Backend ansluten: ${data.service}`);
                })
                .catch(error => {
                    log(`‚ùå Backend fel: ${error}`);
                });
        });
        
        log('üí° Tips: S√§g "Kolla min email", "Vad √§r klockan" eller "Hej Alice"');
    </script>
</body>
</html>